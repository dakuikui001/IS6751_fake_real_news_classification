{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a96bae1",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef6d6359",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata  \n",
    "import inflect       \n",
    "import re\n",
    "from nltk import sent_tokenize\n",
    "from nltk.stem import LancasterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.util import ngrams\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ad5027",
   "metadata": {},
   "source": [
    "## Step 1: Text pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413c6f05",
   "metadata": {},
   "source": [
    "### 1.1 Text Combination and Train_valid_test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a3bfdad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44898, 5)\n",
      "Index(['title', 'text', 'subject', 'date', 'label'], dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 44898 entries, 0 to 44897\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   title    44898 non-null  object\n",
      " 1   text     44898 non-null  object\n",
      " 2   subject  44898 non-null  object\n",
      " 3   date     44898 non-null  object\n",
      " 4   label    44898 non-null  object\n",
      "dtypes: object(5)\n",
      "memory usage: 1.7+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "fake_news_df = pd.read_csv('Data/Fake.csv')\n",
    "true_news_df = pd.read_csv('Data/True.csv')\n",
    "fake_news_df['label'] = 'False'\n",
    "true_news_df['label'] = 'True'\n",
    "news_df = pd.concat([fake_news_df, true_news_df], ignore_index=True, axis=0)\n",
    "print(news_df.shape)\n",
    "print(news_df.columns)\n",
    "print(news_df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a15ec14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44898, 5)\n"
     ]
    }
   ],
   "source": [
    "news_df = news_df[news_df.text.isna() == False]\n",
    "news_df = news_df[news_df.title.isna() == False]\n",
    "news_df = news_df[news_df.subject.isna() == False]\n",
    "print(news_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "066de764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  label\n",
      "0   Donald Trump Sends Out Embarrassing New Year’...  False\n",
      "1   Drunk Bragging Trump Staffer Started Russian ...  False\n",
      "2   Sheriff David Clarke Becomes An Internet Joke...  False\n",
      "3   Trump Is So Obsessed He Even Has Obama’s Name...  False\n",
      "4   Pope Francis Just Called Out Donald Trump Dur...  False\n",
      "label\n",
      "False    23481\n",
      "True     21417\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "news_df['text'] = news_df['title'] + ' ' + news_df['text'] + ' ' + news_df['subject']\n",
    "news_df.drop(['title', 'date', 'subject'], axis=1, inplace=True)\n",
    "print(news_df.head())\n",
    "print(news_df.label.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5005029",
   "metadata": {},
   "outputs": [],
   "source": [
    "by_labels = collections.defaultdict(list)\n",
    "for _, row in news_df.iterrows():\n",
    "    by_labels[row.label].append(row.to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bff5665f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dateset to train, validate and test dataset and stored in list\n",
    "final_list = []\n",
    "np.random.seed(1234)\n",
    "\n",
    "for _, item_list in sorted(by_labels.items()):\n",
    "\n",
    "    np.random.shuffle(item_list)\n",
    "    \n",
    "    n_total = len(item_list)\n",
    "    n_train = int(0.7 * n_total)\n",
    "    n_valid = int(0.15 * n_total)\n",
    "    n_test = n_total - n_train - n_valid\n",
    "    \n",
    "    # Give data point a split attribute\n",
    "    for item in item_list[:n_train]:\n",
    "        item['split'] = 'train'\n",
    "    for item in item_list[n_train:n_train+n_valid]:\n",
    "        item['split'] = 'val'\n",
    "    for item in item_list[n_train+n_valid:]:\n",
    "        item['split'] = 'test'\n",
    "\n",
    "    # Add to final list\n",
    "    final_list.extend(item_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac8d65ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "split\n",
       "train    31427\n",
       "test      6737\n",
       "val       6734\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = pd.DataFrame(final_list)\n",
    "final_df.split.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50c9fc3",
   "metadata": {},
   "source": [
    "### 1.2 Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15f36896",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(words):\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word not in stopwords.words('english'):\n",
    "            new_words.append(word)\n",
    "    return new_words\n",
    "\n",
    "def stem_words(words):\n",
    "    stemmer = LancasterStemmer()\n",
    "    stems = []\n",
    "    for word in words:\n",
    "        stem = stemmer.stem(word)\n",
    "        stems.append(stem)\n",
    "    return stems\n",
    "\n",
    "def lemmatize_verbs(words):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmas = []\n",
    "    for word in words:\n",
    "        lemma = lemmatizer.lemmatize(word, pos='v')\n",
    "        lemmas.append(lemma)\n",
    "    return lemmas\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    if type(text) == float:\n",
    "        print(text)\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"([.,!?])\", r\" \\1 \", text)  # E.g., convert \"end.\" to \"end . \" ; \\1 indicates a matched character\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]+\", r\" \", text) # replace special characters with empty string\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26b99ce8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jake tapper burns trump with bill maher he is ...</td>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>buried by media aide to leftist us congressman...</td>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cnn clown who cries about fake news uses unver...</td>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>delusional obama on how divided america has be...</td>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>veterans cozy trump relationship with russian ...</td>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  split\n",
       "0  jake tapper burns trump with bill maher he is ...  False  train\n",
       "1  buried by media aide to leftist us congressman...  False  train\n",
       "2  cnn clown who cries about fake news uses unver...  False  train\n",
       "3  delusional obama on how divided america has be...  False  train\n",
       "4  veterans cozy trump relationship with russian ...  False  train"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df['text'] = final_df['text'].apply(preprocess_text)\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34e6021a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[jake, tapper, burns, trump, with, bill, maher...</td>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[buried, by, media, aide, to, leftist, us, con...</td>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[cnn, clown, who, cries, about, fake, news, us...</td>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[delusional, obama, on, how, divided, america,...</td>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[veterans, cozy, trump, relationship, with, ru...</td>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  split\n",
       "0  [jake, tapper, burns, trump, with, bill, maher...  False  train\n",
       "1  [buried, by, media, aide, to, leftist, us, con...  False  train\n",
       "2  [cnn, clown, who, cries, about, fake, news, us...  False  train\n",
       "3  [delusional, obama, on, how, divided, america,...  False  train\n",
       "4  [veterans, cozy, trump, relationship, with, ru...  False  train"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df['text'] = final_df['text'].apply(word_tokenize)\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27b7291a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[jake, tapper, burns, trump, bill, maher, empi...</td>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[buried, media, aide, leftist, us, congressman...</td>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[cnn, clown, cries, fake, news, uses, unverifi...</td>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[delusional, obama, divided, america, become, ...</td>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[veterans, cozy, trump, relationship, russian,...</td>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  split\n",
       "0  [jake, tapper, burns, trump, bill, maher, empi...  False  train\n",
       "1  [buried, media, aide, leftist, us, congressman...  False  train\n",
       "2  [cnn, clown, cries, fake, news, uses, unverifi...  False  train\n",
       "3  [delusional, obama, divided, america, become, ...  False  train\n",
       "4  [veterans, cozy, trump, relationship, russian,...  False  train"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df['text'] = final_df['text'].apply(remove_stopwords)\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79a431b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[jak, tap, burn, trump, bil, mah, empir, indec...</td>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[bury, med, aid, leave, us, congressm, sand, l...</td>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[cnn, clown, cri, fak, new, us, unver, story, ...</td>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[delud, obam, divid, americ, becom, least, civ...</td>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[vet, cozy, trump, rel, russ, hack, caus, alar...</td>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  split\n",
       "0  [jak, tap, burn, trump, bil, mah, empir, indec...  False  train\n",
       "1  [bury, med, aid, leave, us, congressm, sand, l...  False  train\n",
       "2  [cnn, clown, cri, fak, new, us, unver, story, ...  False  train\n",
       "3  [delud, obam, divid, americ, becom, least, civ...  False  train\n",
       "4  [vet, cozy, trump, rel, russ, hack, caus, alar...  False  train"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df['text'] = final_df['text'].apply(stem_words)\n",
    "final_df['text'] = final_df['text'].apply(lemmatize_verbs)\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb6b6e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['text'] = final_df['text'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "55a53eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('Data/preprocessed_news.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f0334fea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250.4421132344425"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df['word_length'] = final_df['text'].apply(lambda x: len(x.split()))\n",
    "final_df['word_length'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484337be",
   "metadata": {},
   "source": [
    "# LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "924c23b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "import os\n",
    "import json\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b95a328",
   "metadata": {},
   "source": [
    "## Vocabulary, Vectorizer, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3072f4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary(object):\n",
    "    \"\"\"Class to process text and extract vocabulary for mapping\"\"\"\n",
    "\n",
    "    def __init__(self, token_to_idx=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            token_to_idx (dict): a pre-existing map of tokens to indices\n",
    "        \"\"\"    \n",
    "\n",
    "        if token_to_idx is None:\n",
    "            token_to_idx = {}\n",
    "        self._token_to_idx = token_to_idx         \n",
    "                                                  \n",
    "        self._idx_to_token = {idx: token \n",
    "                              for token, idx in self._token_to_idx.items()}\n",
    "        \n",
    "    def add_token(self, token):\n",
    "        \"\"\"Update mapping dicts based on the token.\n",
    "\n",
    "        Args:\n",
    "            token (str): the item to add into the Vocabulary\n",
    "        Returns:\n",
    "            index (int): the integer corresponding to the token\n",
    "        \"\"\"\n",
    "        if token in self._token_to_idx:\n",
    "            index = self._token_to_idx[token]\n",
    "        else:\n",
    "            index = len(self._token_to_idx)\n",
    "            self._token_to_idx[token] = index\n",
    "            self._idx_to_token[index] = token\n",
    "        return index\n",
    "            \n",
    "    def lookup_token(self, token):\n",
    "        \"\"\"Retrieve the index associated with the token \n",
    "        \n",
    "        Args:\n",
    "            token (str): the token to look up \n",
    "        Returns:\n",
    "            index (int): the index corresponding to the token\n",
    "        \"\"\"\n",
    "        return self._token_to_idx[token]\n",
    "\n",
    "    def lookup_index(self, index):\n",
    "        \"\"\"Return the token associated with the index\n",
    "        \n",
    "        Args: \n",
    "            index (int): the index to look up\n",
    "        Returns:\n",
    "            token (str): the token corresponding to the index\n",
    "        Raises:\n",
    "            KeyError: if the index is not in the Vocabulary\n",
    "        \"\"\"\n",
    "        if index not in self._idx_to_token:\n",
    "            raise KeyError(\"the index (%d) is not in the Vocabulary\" % index)\n",
    "        return self._idx_to_token[index]\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"<Vocabulary(size=%d)>\" % len(self)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._token_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f3e5d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsVocabulary(Vocabulary):\n",
    "    def __init__(self, token_to_idx=None, unk_token=\"<UNK>\",\n",
    "                 mask_token=\"<MASK>\", begin_seq_token=\"<BEGIN>\",\n",
    "                 end_seq_token=\"<END>\"):\n",
    "\n",
    "        super(NewsVocabulary, self).__init__(token_to_idx)\n",
    "\n",
    "        self._mask_token = mask_token  # for paddding, e.g., 'McMahan' -> [2, 5, 6, 5, 7, 8, 7, 9, 3, 0, 0, 0, ..., 0]\n",
    "        self._unk_token = unk_token\n",
    "        self._begin_seq_token = begin_seq_token\n",
    "        self._end_seq_token = end_seq_token\n",
    "\n",
    "        self.mask_index = self.add_token(self._mask_token)           # mask_index is 0\n",
    "        self.unk_index = self.add_token(self._unk_token)             # unk_index is 1\n",
    "        self.begin_seq_index = self.add_token(self._begin_seq_token) # begin_seq_index is 2\n",
    "        self.end_seq_index = self.add_token(self._end_seq_token)     # end_seq_index is 3\n",
    "\n",
    "    def lookup_token(self, token):\n",
    "        \"\"\"Retrieve the index associated with the token \n",
    "          or the UNK index if token isn't present.\n",
    "        \n",
    "        Args:\n",
    "            token (str): the token to look up \n",
    "        Returns:\n",
    "            index (int): the index corresponding to the token\n",
    "        Notes:\n",
    "            `unk_index` needs to be >=0 (having been added into the Vocabulary) \n",
    "              for the UNK functionality \n",
    "        \"\"\"\n",
    "        if self.unk_index >= 0:\n",
    "            return self._token_to_idx.get(token, self.unk_index)\n",
    "        else:\n",
    "            return self._token_to_idx[token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "372c6569",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsVectorizer(object):\n",
    "    \"\"\" The Vectorizer which coordinates the Vocabularies and puts them to use\"\"\"   \n",
    "    def __init__(self, news_vocab, label_vocab):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            news_vocab (NewsVocabulary): maps words to integers\n",
    "            label_vocab (Vocabulary): maps labels to integers\n",
    "        \"\"\"\n",
    "        self.news_vocab = news_vocab\n",
    "        self.label_vocab = label_vocab\n",
    "\n",
    "    def vectorize(self, news, vector_length=-1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            news (str): the string of words\n",
    "            vector_length (int): an argument for forcing the length of index vector\n",
    "        \"\"\"        \n",
    "        # Split text into words and limit the number of words\n",
    "        words = str(news).split(\" \")\n",
    "        \n",
    "        # If vector_length is specified and positive, truncate words to fit\n",
    "        if vector_length > 0:\n",
    "            max_words = vector_length - 2  # Reserve space for begin and end tokens\n",
    "            words = words[:max_words]\n",
    "        \n",
    "        indices = [self.news_vocab.begin_seq_index]\n",
    "        indices.extend(self.news_vocab.lookup_token(token) \n",
    "                       for token in words)\n",
    "        indices.append(self.news_vocab.end_seq_index)\n",
    "\n",
    "        if vector_length < 0:\n",
    "            vector_length = len(indices)\n",
    "\n",
    "        out_vector = np.zeros(vector_length, dtype=np.int64)   # Fixed size vector\n",
    "        out_vector[:len(indices)] = indices\n",
    "        out_vector[len(indices):] = self.news_vocab.mask_index\n",
    "        \n",
    "        return out_vector, len(indices)\n",
    "\n",
    "    @classmethod\n",
    "    def from_dataframe(cls, news_df):\n",
    "        \"\"\"Instantiate the vectorizer from the dataset dataframe\n",
    "        \n",
    "        Args:\n",
    "            news_df (pandas.DataFrame): the news dataset\n",
    "        Returns:\n",
    "            an instance of the NewsVectorizer\n",
    "        \"\"\"\n",
    "        news_vocab = NewsVocabulary() # add mask, unknown, begin_seq, and end_seq tokens to the token_to_index dictionary\n",
    "        label_vocab = Vocabulary()\n",
    "        \n",
    "        for index, row in news_df.iterrows():\n",
    "            for word in str(row.text).split(\" \"):\n",
    "                news_vocab.add_token(word)\n",
    "            label_vocab.add_token(row.label)\n",
    "\n",
    "        return cls(news_vocab, label_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8498c6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsDataset(Dataset):\n",
    "    def __init__(self, news_df, vectorizer, max_seq_length=512):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            news_df (pandas.DataFrame): the dataset\n",
    "            vectorizer (NewsVectorizer): vectorizer instatiated from dataset\n",
    "            max_seq_length (int): maximum sequence length to prevent memory issues\n",
    "        \"\"\"\n",
    "        self.news_df = news_df \n",
    "        self._vectorizer = vectorizer\n",
    "\n",
    "        # Use the specified max_seq_length directly\n",
    "        self._max_seq_length = max_seq_length\n",
    "\n",
    "        self.train_df = self.news_df[self.news_df.split=='train']\n",
    "        self.train_size = len(self.train_df)\n",
    "\n",
    "        self.val_df = self.news_df[self.news_df.split=='val']\n",
    "        self.validation_size = len(self.val_df)\n",
    "\n",
    "        self.test_df = self.news_df[self.news_df.split=='test']\n",
    "        self.test_size = len(self.test_df)\n",
    "\n",
    "        self._lookup_dict = {'train': (self.train_df, self.train_size), \n",
    "                             'val': (self.val_df, self.validation_size), \n",
    "                             'test': (self.test_df, self.test_size)}\n",
    "\n",
    "        self.set_split('train')\n",
    "        \n",
    "        # Class weights for binary classification\n",
    "        class_counts = self.train_df.label.value_counts().to_dict()   # {'False': count1, 'True': count2}\n",
    "        def sort_key(item):\n",
    "            return self._vectorizer.label_vocab.lookup_token(item[0]) # e.g, index of False is 0, True is 1\n",
    "        sorted_counts = sorted(class_counts.items(), key=sort_key)          # sort by the index number of label_vocab\n",
    "                                   # {('False', count1), ('True', count2)}\n",
    "        frequencies = [count for _, count in sorted_counts]\n",
    "        self.class_weights = 1.0 / torch.tensor(frequencies, dtype=torch.float32) # [1/count1, 1/count2]\n",
    "\n",
    "        \n",
    "    @classmethod\n",
    "    def load_dataset_and_make_vectorizer(cls, news_csv, max_seq_length=512):\n",
    "        \"\"\"Load dataset and make a new vectorizer from scratch\n",
    "        \n",
    "        Args:\n",
    "            news_csv (str): location of the dataset\n",
    "            max_seq_length (int): maximum sequence length to prevent memory issues\n",
    "        Returns:\n",
    "            an instance of NewsDataset\n",
    "        \"\"\"\n",
    "        news_df = pd.read_csv(news_csv)\n",
    "        train_news_df = news_df[news_df.split=='train']\n",
    "        return cls(news_df, NewsVectorizer.from_dataframe(train_news_df), max_seq_length)\n",
    "        \n",
    "    def get_vectorizer(self):\n",
    "        \"\"\" returns the vectorizer \"\"\"\n",
    "        return self._vectorizer\n",
    "\n",
    "    def set_split(self, split=\"train\"):\n",
    "        self._target_split = split\n",
    "        self._target_df, self._target_size = self._lookup_dict[split]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._target_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"the primary entry point method for PyTorch datasets\n",
    "        \n",
    "        Args:\n",
    "            index (int): the index to the data point \n",
    "        Returns:\n",
    "            a dictionary holding the data point's:\n",
    "                features (x_data)\n",
    "                label (y_target)\n",
    "                feature length (x_length)\n",
    "        \"\"\"\n",
    "        row = self._target_df.iloc[index]\n",
    "        \n",
    "        news_vector, vec_length = \\\n",
    "            self._vectorizer.vectorize(row.text, self._max_seq_length)\n",
    "        \n",
    "        label_index = \\\n",
    "            self._vectorizer.label_vocab.lookup_token(row.label)\n",
    "\n",
    "        return {'x_data': news_vector,      # 'x_data': [2, 5, 6, 5, 7, 8, 7, 9, 3, 0, 0, 0, ..., 0] when news is processed\n",
    "                'y_target': label_index, # 'y_target': 0 for False, 1 for True              \n",
    "                'x_length': vec_length}        # 'x_length': sequence length\n",
    "    \n",
    "    def get_num_batches(self, batch_size):\n",
    "        \"\"\"Given a batch size, return the number of batches in the dataset\n",
    "        \n",
    "        Args:\n",
    "            batch_size (int)\n",
    "        Returns:\n",
    "            number of batches in the dataset\n",
    "        \"\"\"\n",
    "        return len(self) // batch_size   \n",
    "\n",
    "def generate_batches(dataset, batch_size, shuffle=True,\n",
    "                     drop_last=True, device=\"cpu\"): \n",
    "    \"\"\"\n",
    "    A generator function which wraps the PyTorch DataLoader. It will \n",
    "      ensure each tensor is on the write device location.\n",
    "    \"\"\"\n",
    "    dataloader = DataLoader(dataset=dataset, batch_size=batch_size,\n",
    "                            shuffle=shuffle, drop_last=drop_last)\n",
    "\n",
    "    for data_dict in dataloader:\n",
    "        out_data_dict = {}\n",
    "        for name, tensor in data_dict.items():\n",
    "            out_data_dict[name] = data_dict[name].to(device)\n",
    "        yield out_data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db06ac7",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "85a15844",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def column_gather(y_out, x_lengths):\n",
    "    '''Get a specific vector from each batch datapoint in `y_out`.\n",
    "\n",
    "    More precisely, iterate over batch row indices, get the vector that's at\n",
    "    the position indicated by the corresponding value in `x_lengths` at the row\n",
    "    index.\n",
    "\n",
    "    Args:\n",
    "        y_out (torch.FloatTensor, torch.cuda.FloatTensor)\n",
    "            shape: (batch, sequence, feature)\n",
    "        x_lengths (torch.LongTensor, torch.cuda.LongTensor)\n",
    "            shape: (batch,)\n",
    "\n",
    "    Returns:\n",
    "        y_out (torch.FloatTensor, torch.cuda.FloatTensor)\n",
    "            shape: (batch, feature)\n",
    "    '''\n",
    "    x_lengths = x_lengths.long().detach().cpu().numpy() - 1   # deduct 1 since the index starts from 0\n",
    "                                                              # e.g., [9, 6, 11, 9, 7, ...., 12]\n",
    "    out = []\n",
    "    for batch_index, column_index in enumerate(x_lengths): # out gets the last hidden vector of each input: (batch, hidden_size)\n",
    "        out.append(y_out[batch_index, column_index]) # e.g., y_out[0, 9], y_out[1, 6]\n",
    "\n",
    "    return torch.stack(out)  # (batch, hidden_size*num_directions); E.g., (64, 64*num_direction)\n",
    "\n",
    "def column_summation(y_out, x_lengths, mode=\"mean\"):\n",
    "    '''Get a max or mean vector from each batch datapoint in `y_out`.\n",
    "\n",
    "    More precisely, iterate over batch row indices, get the max or mean vector of all the vectors by \n",
    "    the position indicated by the corresponding value in `x_lengths` at the row index.\n",
    "\n",
    "    Args:\n",
    "        y_out (torch.FloatTensor, torch.cuda.FloatTensor)\n",
    "            shape: (batch, sequence, feature)\n",
    "        x_lengths (torch.LongTensor, torch.cuda.LongTensor)\n",
    "            shape: (batch,)\n",
    "        mode: \"mean\" for mean vector; \"max\" for max vector\n",
    "\n",
    "    Returns:\n",
    "        y_out (torch.FloatTensor, torch.cuda.FloatTensor)\n",
    "            shape: (batch, feature)\n",
    "    '''\n",
    "    x_lengths = x_lengths.long().detach().cpu().numpy() - 1\n",
    "\n",
    "    out = []\n",
    "    for batch_index, column_index in enumerate(x_lengths):\n",
    "        if mode == \"mean\":\n",
    "            # replace \"pass\" with your code to get the mean vector of current batch item from y_out[], and append it to out list.\n",
    "            out.append(y_out[batch_index, :column_index + 1].mean(dim=0))\n",
    "        else:      # mode == \"max\"\n",
    "            # replace \"pass\" with your code to get the max vector of current batch item from y_out[], , and append it to out list.\n",
    "            out.append(y_out[batch_index, :column_index + 1].max(dim=0).values)\n",
    "\n",
    "    return torch.stack(out)\n",
    "\n",
    "class NewsClassifier(nn.Module):\n",
    "    \"\"\" A Classifier with an RNN to extract features and an MLP to classify \"\"\"\n",
    "    def __init__(self, embedding_size, num_embeddings, num_classes,\n",
    "                 rnn_hidden_size, bidirectional=False, batch_first=True, padding_idx=0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            embedding_size (int): The size of the character embeddings\n",
    "            num_embeddings (int): The number of characters to embed\n",
    "            num_classes (int): The size of the prediction vector \n",
    "                Note: For binary classification, this should be 1\n",
    "            bidirectional (bool): Informs whether bidrectional RNN is used\n",
    "            rnn_hidden_size (int): The size of the RNN's hidden state\n",
    "            batch_first (bool): Informs whether the input tensors will \n",
    "                have batch or the sequence on the 0th dimension\n",
    "            padding_idx (int): The index for the tensor padding; \n",
    "                see torch.nn.Embedding\n",
    "        \"\"\"\n",
    "        super(NewsClassifier, self).__init__()\n",
    "\n",
    "        if bidirectional == False:\n",
    "             self.num_directions = 1\n",
    "        else:\n",
    "             self.num_directions = 2\n",
    "        \n",
    "        self.emb = nn.Embedding(num_embeddings=num_embeddings,    # E.g., (80, 100)\n",
    "                                embedding_dim=embedding_size,\n",
    "                                padding_idx=padding_idx)          # mask_index (padding index) is 0\n",
    "\n",
    "        #self.rnn = nn.RNN(input_size=embedding_size,              # E.g., 100\n",
    "        #self.rnn = nn.GRU(input_size=embedding_size,\n",
    "        self.rnn = nn.LSTM(input_size=embedding_size,\n",
    "                             hidden_size=rnn_hidden_size,         # E.g., 64\n",
    "                             batch_first=batch_first, \n",
    "                             num_layers = 1,\n",
    "                             dropout = 0.0, \n",
    "                             bidirectional=bidirectional)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=rnn_hidden_size*self.num_directions,  # 64*1 for unidirectinal; 64*2 for bidirectional\n",
    "                         out_features=rnn_hidden_size*self.num_directions)\n",
    "        self.fc2 = nn.Linear(in_features=rnn_hidden_size*self.num_directions,\n",
    "                          out_features=1)                            # 1 output for binary classification\n",
    "        # for batch norm & dropout\n",
    "        self.bn1 = nn.BatchNorm1d(rnn_hidden_size*self.num_directions) \n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "\n",
    "    def forward(self, x_in, x_lengths=None, apply_softmax=False):\n",
    "        \"\"\"The forward pass of the classifier\n",
    "        \n",
    "        Args:\n",
    "            x_in (torch.Tensor): an input data tensor. \n",
    "                x_in.shape should be (batch, input_dim, i.e. seq_size)\n",
    "            x_lengths (torch.Tensor): the lengths of each sequence in the batch.\n",
    "                They are used to find the final vector of each sequence: (batch,)\n",
    "            apply_softmax (bool): a flag for the softmax activation\n",
    "                should be false if used with the Cross Entropy losses\n",
    "        Returns:\n",
    "            the resulting tensor. tensor.shape should be (batch, 1) for binary classification\n",
    "        \"\"\"\n",
    "        x_embedded = self.emb(x_in)      # (batch, seq_size)->(batch, seq_size, feat_size) ; E.g., (64,19)->(64,19,100)\n",
    "        \n",
    "        y_out, _ = self.rnn(x_embedded)  # (batch, seq_size, feat_size) -> (batch, seq_size, hidden_size*num_directions)\n",
    "                                         # (64,19,100) -> (64,19,64*num_directions)\n",
    "      \n",
    "        if x_lengths is not None:        # (batch, ) ; e.g., (64,) ; e.g., [9, 6, 11, 9, 7, ...., 12]\n",
    "            #y_out = column_gather(y_out, x_lengths)  # y_out gets the last hidden vector of each input: (batch, hidden_size*num_directions)\n",
    "                                                     # (64, 64*num_direction)\n",
    "                                                     # but, the last hidden vector of last character, not including padding\n",
    "                                                     # e.g., get the last hidden vetor from y_out[batch_no, 9] instead of y_out[batch_no, 18].\n",
    "\n",
    "            # uncomment code below for task 2, and comment out the line above.\n",
    "            # y_out gets the max or mean hidden vector of each input\n",
    "            y_out = column_summation(y_out, x_lengths, mode=\"mean\") \n",
    "        else:\n",
    "            y_out = y_out[:, -1, :]      # y_out gets the last hidden vector of each input: (batch, hidden_size*num_directions)\n",
    "                                         # (64, 64*num_direction)\n",
    "            \n",
    "        # with batch norm and dropout\n",
    "        # F.dropout(y_out, 0.2, training=self.training) can also be used as an alternative to self.dropout(y_out) \n",
    "        y_out = F.relu(self.bn1(self.fc1(self.dropout(y_out))))  # y_out: (64, 64*num_direction)\n",
    "\n",
    "        \n",
    "        # with dropout\n",
    "        y_out = self.fc2(self.dropout(y_out))   # y_out: (batch, 1) for binary classification\n",
    "\n",
    "        if apply_softmax:\n",
    "            y_out = torch.sigmoid(y_out)  # Use sigmoid for binary classification instead of softmax\n",
    "\n",
    "        return y_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0fc7e031",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed_everywhere(seed, cuda):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if cuda:\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def handle_dirs(dirpath):\n",
    "    if not os.path.exists(dirpath):\n",
    "        os.makedirs(dirpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997a9d50",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ac262ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA: False\n"
     ]
    }
   ],
   "source": [
    "args = Namespace(\n",
    "    # Data and path information\n",
    "    output_news_csv='Data/preprocessed_news.csv',\n",
    "    model_state_file=\"model.pth\",\n",
    "    save_dir=\"model_storage/ch6/news_classification\",\n",
    "    # Model hyper parameter\n",
    "    char_embedding_size=100,\n",
    "    rnn_hidden_size=64,\n",
    "    bidirectional=False,\n",
    "    # Training hyper parameter\n",
    "    num_epochs=100,  # Reduced from 100 to 10 for testing\n",
    "    learning_rate=1e-3,\n",
    "    batch_size=64,  # Reduced from 64 to 32 to save memory\n",
    "    seed=1337,\n",
    "    early_stopping_criteria=5,\n",
    "    # Runtime hyper parameter\n",
    "    cuda=True,\n",
    "    catch_keyboard_interrupt=True,\n",
    "    expand_filepaths_to_save_dir=True,\n",
    ")\n",
    "\n",
    "# Check CUDA\n",
    "if not torch.cuda.is_available():\n",
    "    args.cuda = False\n",
    "\n",
    "args.device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
    "    \n",
    "print(\"Using CUDA: {}\".format(args.cuda))\n",
    "\n",
    "\n",
    "if args.expand_filepaths_to_save_dir:\n",
    "    args.model_state_file = os.path.join(args.save_dir, args.model_state_file)\n",
    "    \n",
    "# Set seed for reproducibility\n",
    "set_seed_everywhere(args.seed, args.cuda)\n",
    "\n",
    "# handle dirs\n",
    "handle_dirs(args.save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "661c3cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset and vectorizer with limited sequence length\n",
    "dataset = NewsDataset.load_dataset_and_make_vectorizer(args.output_news_csv, max_seq_length=512)\n",
    "\n",
    "vectorizer = dataset.get_vectorizer()\n",
    "\n",
    "classifier = NewsClassifier(embedding_size=args.char_embedding_size, \n",
    "                               num_embeddings=len(vectorizer.news_vocab),\n",
    "                               num_classes=1,  # Binary classification\n",
    "                               rnn_hidden_size=args.rnn_hidden_size,\n",
    "                               padding_idx=vectorizer.news_vocab.mask_index,\n",
    "                               bidirectional=args.bidirectional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7bdcfa0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing data loading...\n",
      "Original text length: 1500 words\n",
      "Vectorized length: 512\n",
      "Vector shape: (512,)\n",
      "Max sequence length: 512\n",
      "Batch shape: torch.Size([2, 512])\n",
      "Target shape: torch.Size([2])\n",
      "Length shape: torch.Size([2])\n",
      "Data loading test passed!\n"
     ]
    }
   ],
   "source": [
    "# Test data loading to ensure everything works\n",
    "print(\"Testing data loading...\")\n",
    "dataset.set_split('train')\n",
    "\n",
    "# Test vectorization with a long text\n",
    "test_text = \"This is a very long text that should be truncated properly when we vectorize it. \" * 100\n",
    "print(f\"Original text length: {len(test_text.split())} words\")\n",
    "\n",
    "vectorized, length = dataset._vectorizer.vectorize(test_text, dataset._max_seq_length)\n",
    "print(f\"Vectorized length: {length}\")\n",
    "print(f\"Vector shape: {vectorized.shape}\")\n",
    "print(f\"Max sequence length: {dataset._max_seq_length}\")\n",
    "\n",
    "# Test batch loading\n",
    "test_batch = next(iter(generate_batches(dataset, batch_size=2, device=args.device)))\n",
    "print(f\"Batch shape: {test_batch['x_data'].shape}\")\n",
    "print(f\"Target shape: {test_batch['y_target'].shape}\")\n",
    "print(f\"Length shape: {test_batch['x_length'].shape}\")\n",
    "print(\"Data loading test passed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a5960a23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset._max_seq_length # max sequence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "46a807c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<MASK>': 0,\n",
       " '<UNK>': 1,\n",
       " '<BEGIN>': 2,\n",
       " '<END>': 3,\n",
       " 'jak': 4,\n",
       " 'tap': 5,\n",
       " 'burn': 6,\n",
       " 'trump': 7,\n",
       " 'bil': 8,\n",
       " 'mah': 9,\n",
       " 'empir': 10,\n",
       " 'indec': 11,\n",
       " 'video': 12,\n",
       " 'lot': 13,\n",
       " 'americ': 14,\n",
       " 'chang': 15,\n",
       " 'sint': 16,\n",
       " 'ris': 17,\n",
       " 'donald': 18,\n",
       " 'peopl': 19,\n",
       " 'think': 20,\n",
       " 'coars': 21,\n",
       " 'langu': 22,\n",
       " 'clear': 23,\n",
       " 'rac': 24,\n",
       " 'misogyny': 25,\n",
       " 'gen': 26,\n",
       " 'appal': 27,\n",
       " 'behavy': 28,\n",
       " 'would': 29,\n",
       " 'rend': 30,\n",
       " 'unacceiv': 31,\n",
       " 'be': 32,\n",
       " 'publ': 33,\n",
       " 'yet': 34,\n",
       " 'presid': 35,\n",
       " 'young': 36,\n",
       " 'admin': 37,\n",
       " 'funda': 38,\n",
       " 'world': 39,\n",
       " 'view': 40,\n",
       " 'cit': 41,\n",
       " 'govern': 42,\n",
       " 'on': 43,\n",
       " 'thing': 44,\n",
       " 'though': 45,\n",
       " 'way': 46,\n",
       " 'strident': 47,\n",
       " 'brav': 48,\n",
       " 'med': 49,\n",
       " 'person': 50,\n",
       " 'continu': 51,\n",
       " 'speak': 52,\n",
       " 'tru': 53,\n",
       " 'pow': 54,\n",
       " 'insist': 55,\n",
       " 'mak': 56,\n",
       " 'sur': 57,\n",
       " 'disgust': 58,\n",
       " 'incompet': 59,\n",
       " 'lie': 60,\n",
       " 'perhap': 61,\n",
       " 'breakout': 62,\n",
       " 'star': 63,\n",
       " 'regard': 64,\n",
       " 'cnn': 65,\n",
       " 'host': 66,\n",
       " 'lead': 67,\n",
       " 'week': 68,\n",
       " 'stat': 69,\n",
       " 'un': 70,\n",
       " 'sunday': 71,\n",
       " 'morn': 72,\n",
       " 'friday': 73,\n",
       " 'night': 74,\n",
       " 'fiery': 75,\n",
       " 'stop': 76,\n",
       " 'hbo': 77,\n",
       " 'real': 78,\n",
       " 'tim': 79,\n",
       " 'chat': 80,\n",
       " 'cours': 81,\n",
       " 'ask': 82,\n",
       " 'biggest': 83,\n",
       " 'liar': 84,\n",
       " 'ear': 85,\n",
       " 'occupy': 86,\n",
       " 'ov': 87,\n",
       " 'off': 88,\n",
       " 'respond': 89,\n",
       " 'cov': 90,\n",
       " 'polit': 91,\n",
       " 'long': 92,\n",
       " 'inv': 93,\n",
       " 'jan': 94,\n",
       " '20': 95,\n",
       " 'nev': 96,\n",
       " 'see': 97,\n",
       " 'level': 98,\n",
       " 'fals': 99,\n",
       " 'quantit': 100,\n",
       " 'go': 101,\n",
       " 'distinct': 102,\n",
       " 'hap': 103,\n",
       " 'say': 104,\n",
       " 'obam': 105,\n",
       " 'lik': 106,\n",
       " 'doct': 107,\n",
       " 'keep': 108,\n",
       " 'com': 109,\n",
       " 'whit': 110,\n",
       " 'hous': 111,\n",
       " 'conspir': 112,\n",
       " 'the': 113,\n",
       " 'bas': 114,\n",
       " 'noth': 115,\n",
       " 'memb': 116,\n",
       " 'party': 117,\n",
       " 'dist': 118,\n",
       " 'convers': 119,\n",
       " 'turn': 120,\n",
       " 'vulg': 121,\n",
       " 'affront': 122,\n",
       " 'hum': 123,\n",
       " 'dec': 124,\n",
       " 'discours': 125,\n",
       " 'behav': 126,\n",
       " 'campaign': 127,\n",
       " 'trail': 128,\n",
       " 'mat': 129,\n",
       " 'bia': 130,\n",
       " 'fact': 131,\n",
       " 'fun': 132,\n",
       " 'dis': 133,\n",
       " 'childr': 134,\n",
       " 'know': 135,\n",
       " 'bet': 136,\n",
       " 'two': 137,\n",
       " 'ref': 138,\n",
       " 'aw': 139,\n",
       " 'learn': 140,\n",
       " 'grad': 141,\n",
       " 'school': 142,\n",
       " 'alway': 143,\n",
       " 'book': 144,\n",
       " 'everyth': 145,\n",
       " 'nee': 146,\n",
       " 'kindergart': 147,\n",
       " 'viol': 148,\n",
       " 'every': 149,\n",
       " 'rul': 150,\n",
       " 'accus': 151,\n",
       " 'guil': 152,\n",
       " 'boast': 153,\n",
       " 'pay': 154,\n",
       " 'tax': 155,\n",
       " 'serv': 156,\n",
       " 'country': 157,\n",
       " 'insult': 158,\n",
       " 'handicap': 159,\n",
       " 'lucky': 160,\n",
       " 'gre': 161,\n",
       " 'look': 162,\n",
       " 'spit': 163,\n",
       " 'stil': 164,\n",
       " 'vot': 165,\n",
       " 'sorry': 166,\n",
       " 'excus': 167,\n",
       " 'nat': 168,\n",
       " 'examin': 169,\n",
       " 'surv': 170,\n",
       " 'nightm': 171,\n",
       " 'watch': 172,\n",
       " 'feat': 173,\n",
       " 'im': 174,\n",
       " 'via': 175,\n",
       " 'scot': 176,\n",
       " 'eis': 177,\n",
       " 'getty': 178,\n",
       " 'new': 179,\n",
       " 'bury': 180,\n",
       " 'aid': 181,\n",
       " 'leave': 182,\n",
       " 'us': 183,\n",
       " 'congressm': 184,\n",
       " 'sand': 185,\n",
       " 'levin': 186,\n",
       " 'mi': 187,\n",
       " 'arrest': 188,\n",
       " 'brut': 189,\n",
       " 'beat': 190,\n",
       " 'mal': 191,\n",
       " 'lov': 192,\n",
       " 'shovel': 193,\n",
       " 'want': 194,\n",
       " 'kil': 195,\n",
       " 'die': 196,\n",
       " 'dirty': 197,\n",
       " 'faggy': 198,\n",
       " 'muslim': 199,\n",
       " 'corn': 200,\n",
       " 'market': 201,\n",
       " 'abus': 202,\n",
       " 'gay': 203,\n",
       " 'story': 204,\n",
       " 'mainstream': 205,\n",
       " 'pleas': 206,\n",
       " 'feel': 207,\n",
       " 'fre': 208,\n",
       " 'shar': 209,\n",
       " 'baltim': 210,\n",
       " 'city': 211,\n",
       " 'pol': 212,\n",
       " 'rep': 213,\n",
       " 'mich': 214,\n",
       " 'around': 215,\n",
       " '2': 216,\n",
       " '30': 217,\n",
       " 'oct': 218,\n",
       " '8': 219,\n",
       " 'crimin': 220,\n",
       " 'domest': 221,\n",
       " 'charg': 222,\n",
       " 'fost': 223,\n",
       " 'henderson': 224,\n",
       " 'ky': 225,\n",
       " 'smal': 226,\n",
       " 'black': 227,\n",
       " 'red': 228,\n",
       " 'accord': 229,\n",
       " 'report': 230,\n",
       " 'obtain': 231,\n",
       " 'cq': 232,\n",
       " 'rol': 233,\n",
       " 'cal': 234,\n",
       " 'leav': 235,\n",
       " 'victim': 236,\n",
       " 'hospit': 237,\n",
       " 'abras': 238,\n",
       " 'bru': 239,\n",
       " 'up': 240,\n",
       " 'back': 241,\n",
       " 'neck': 242,\n",
       " 'torso': 243,\n",
       " 'disput': 244,\n",
       " 'start': 245,\n",
       " '12': 246,\n",
       " 'insid': 247,\n",
       " 'northwest': 248,\n",
       " 'hom': 249,\n",
       " '32': 250,\n",
       " 'get': 251,\n",
       " 'verb': 252,\n",
       " 'argu': 253,\n",
       " '39': 254,\n",
       " 'year': 255,\n",
       " 'old': 256,\n",
       " 'ident': 257,\n",
       " 'boyfriend': 258,\n",
       " 'put': 259,\n",
       " 'chok': 260,\n",
       " 'hold': 261,\n",
       " 'man': 262,\n",
       " 'lat': 263,\n",
       " 'tell': 264,\n",
       " 'releas': 265,\n",
       " 'alleg': 266,\n",
       " 'grab': 267,\n",
       " 'stainless': 268,\n",
       " 'kitch': 269,\n",
       " 'knif': 270,\n",
       " 'flee': 271,\n",
       " 'toward': 272,\n",
       " 'stair': 273,\n",
       " 'chas': 274,\n",
       " 'warn': 275,\n",
       " 'reach': 276,\n",
       " 'fif': 277,\n",
       " 'step': 278,\n",
       " 'stab': 279,\n",
       " 'lung': 280,\n",
       " 'wif': 281,\n",
       " 'fel': 282,\n",
       " 'flo': 283,\n",
       " 'attempt': 284,\n",
       " 'escap': 285,\n",
       " 'property': 286,\n",
       " 'assault': 287,\n",
       " 'strike': 288,\n",
       " 'vehic': 289,\n",
       " 'mem': 290,\n",
       " 'spok': 291,\n",
       " 'plac': 292,\n",
       " 'thursday': 293,\n",
       " 'lock': 294,\n",
       " 'county': 295,\n",
       " 'det': 296,\n",
       " 'cent': 297,\n",
       " 'submit': 298,\n",
       " 'evid': 299,\n",
       " 'court': 300,\n",
       " 'record': 301,\n",
       " 'show': 302,\n",
       " 'commit': 303,\n",
       " 'overnight': 304,\n",
       " 'fac': 305,\n",
       " 'second': 306,\n",
       " 'degr': 307,\n",
       " 'dang': 308,\n",
       " 'weapon': 309,\n",
       " 'employ': 310,\n",
       " 'sev': 311,\n",
       " 'cur': 312,\n",
       " 'post': 313,\n",
       " 'onlin': 314,\n",
       " 'commun': 315,\n",
       " 'may': 316,\n",
       " '2013': 317,\n",
       " 'wak': 318,\n",
       " 'incid': 319,\n",
       " 'unpaid': 320,\n",
       " 'clown': 321,\n",
       " 'cri': 322,\n",
       " 'fak': 323,\n",
       " 'unver': 324,\n",
       " 'push': 325,\n",
       " 'islamaphob': 326,\n",
       " 'youtub': 327,\n",
       " 'prankst': 328,\n",
       " 'nam': 329,\n",
       " 'adam': 330,\n",
       " 'saleh': 331,\n",
       " 'claim': 332,\n",
       " 'kick': 333,\n",
       " 'delt': 334,\n",
       " 'flight': 335,\n",
       " 'arab': 336,\n",
       " 'airlin': 337,\n",
       " 'conclud': 338,\n",
       " 'investig': 339,\n",
       " 'eng': 340,\n",
       " 'provac': 341,\n",
       " 'https': 342,\n",
       " 'www': 343,\n",
       " 'v': 344,\n",
       " '5': 345,\n",
       " 's5gs0i4uw': 346,\n",
       " 'interview': 347,\n",
       " 'hil': 348,\n",
       " 'form': 349,\n",
       " 'mediait': 350,\n",
       " 'column': 351,\n",
       " 'joe': 352,\n",
       " 'conch': 353,\n",
       " 'carlson': 354,\n",
       " 'stelt': 355,\n",
       " 'regul': 356,\n",
       " 'urg': 357,\n",
       " 'org': 358,\n",
       " 'process': 359,\n",
       " 'caut': 360,\n",
       " 'cas': 361,\n",
       " 'fail': 362,\n",
       " 'pract': 363,\n",
       " 'preach': 364,\n",
       " 'googl': 365,\n",
       " 'discov': 366,\n",
       " 'hist': 367,\n",
       " 'simil': 368,\n",
       " 'mediaitein': 369,\n",
       " 'custom': 370,\n",
       " 'remov': 371,\n",
       " 'rebook': 372,\n",
       " 'disturb': 373,\n",
       " 'cabin': 374,\n",
       " 'result': 375,\n",
       " 'express': 376,\n",
       " 'discomfort': 377,\n",
       " 'conduc': 378,\n",
       " 'ful': 379,\n",
       " 'review': 380,\n",
       " 'understand': 381,\n",
       " 'transpir': 382,\n",
       " 'tak': 383,\n",
       " 'discrimin': 384,\n",
       " 'sery': 385,\n",
       " 'cult': 386,\n",
       " 'requir': 387,\n",
       " 'tre': 388,\n",
       " 'oth': 389,\n",
       " 'respect': 390,\n",
       " '1': 391,\n",
       " '6': 392,\n",
       " 'mil': 393,\n",
       " 'subscrib': 394,\n",
       " 'truestoryas': 395,\n",
       " 'channel': 396,\n",
       " 'vlog': 397,\n",
       " 'prank': 398,\n",
       " 'wel': 399,\n",
       " 'lif': 400,\n",
       " 'self': 401,\n",
       " 'describ': 402,\n",
       " 'profess': 403,\n",
       " 'idiot': 404,\n",
       " 'twit': 405,\n",
       " 'deltaclick': 406,\n",
       " 'facebookcal': 407,\n",
       " '800': 408,\n",
       " '221': 409,\n",
       " '1212': 410,\n",
       " 'servicelet': 411,\n",
       " 'stand': 412,\n",
       " 'decid': 413,\n",
       " 'ter': 414,\n",
       " 'islam': 415,\n",
       " 'rad': 416,\n",
       " 'innoc': 417,\n",
       " 'laugh': 418,\n",
       " 'delud': 419,\n",
       " 'divid': 420,\n",
       " 'becom': 421,\n",
       " 'least': 422,\n",
       " 'civil': 423,\n",
       " 'war': 424,\n",
       " 'vet': 425,\n",
       " 'cozy': 426,\n",
       " 'rel': 427,\n",
       " 'russ': 428,\n",
       " 'hack': 429,\n",
       " 'caus': 430,\n",
       " 'alarm': 431,\n",
       " 'milit': 432,\n",
       " 'extrem': 433,\n",
       " 'concern': 434,\n",
       " 'react': 435,\n",
       " 'revel': 436,\n",
       " 'stol': 437,\n",
       " 'inform': 438,\n",
       " 'democr': 439,\n",
       " 'pass': 440,\n",
       " 'wikileak': 441,\n",
       " 'influ': 442,\n",
       " 'elect': 443,\n",
       " 'congress': 444,\n",
       " 'republ': 445,\n",
       " 'play': 446,\n",
       " 'retir': 447,\n",
       " 'maj': 448,\n",
       " 'paul': 449,\n",
       " 'eaton': 450,\n",
       " 'seny': 451,\n",
       " 'adv': 452,\n",
       " 'votevet': 453,\n",
       " 'blast': 454,\n",
       " 'mom': 455,\n",
       " 'unit': 456,\n",
       " 'enam': 457,\n",
       " 'regim': 458,\n",
       " 'sec': 459,\n",
       " 'pot': 460,\n",
       " 'secret': 461,\n",
       " 'find': 462,\n",
       " 'interf': 463,\n",
       " 'help': 464,\n",
       " 'sid': 465,\n",
       " 'join': 466,\n",
       " 'sen': 467,\n",
       " 'wyd': 468,\n",
       " 'intellig': 469,\n",
       " 'declass': 470,\n",
       " 'immedy': 471,\n",
       " 'also': 472,\n",
       " 'group': 473,\n",
       " '10': 474,\n",
       " 'colleg': 475,\n",
       " 'rec': 476,\n",
       " 'tel': 477,\n",
       " 'cia': 478,\n",
       " 'deserv': 479,\n",
       " 'right': 480,\n",
       " 'anyon': 481,\n",
       " 'connect': 482,\n",
       " 'plot': 483,\n",
       " 'manip': 484,\n",
       " 'outcom': 485,\n",
       " '2016': 486,\n",
       " 'induc': 487,\n",
       " 'fear': 488,\n",
       " 'among': 489,\n",
       " 'act': 490,\n",
       " 'putin': 491,\n",
       " 'dir': 492,\n",
       " 'term': 493,\n",
       " 'fresh': 494,\n",
       " 'part': 495,\n",
       " 'benghaz': 496,\n",
       " 'larg': 497,\n",
       " 'whip': 498,\n",
       " 'attack': 499,\n",
       " 'clinton': 500,\n",
       " 'slow': 501,\n",
       " 'walk': 502,\n",
       " 'respons': 503,\n",
       " 'oppos': 504,\n",
       " 'sort': 505,\n",
       " 'could': 506,\n",
       " 'harm': 507,\n",
       " 'nyc': 508,\n",
       " 'park': 509,\n",
       " 'mock': 510,\n",
       " 'nak': 511,\n",
       " 'statu': 512,\n",
       " 'appear': 513,\n",
       " 'art': 514,\n",
       " 'instal': 515,\n",
       " 'sculpt': 516,\n",
       " 'behind': 517,\n",
       " 'phys': 518,\n",
       " 'metaph': 519,\n",
       " 'embody': 520,\n",
       " 'ghast': 521,\n",
       " 'soul': 522,\n",
       " 'infam': 523,\n",
       " 'revil': 524,\n",
       " 'interest': 525,\n",
       " 'enough': 526,\n",
       " 'depict': 527,\n",
       " 'est': 528,\n",
       " 'mog': 529,\n",
       " 'televid': 530,\n",
       " 'egomaniac': 531,\n",
       " 'remark': 532,\n",
       " 'lifelik': 533,\n",
       " 'york': 534,\n",
       " 'squ': 535,\n",
       " 'whoev': 536,\n",
       " 'last': 537,\n",
       " 'pic': 538,\n",
       " 'cldd4qkgyi': 539,\n",
       " 'jamesmichael': 540,\n",
       " 'nichol': 541,\n",
       " 'august': 542,\n",
       " '18': 543,\n",
       " '2016clearly': 544,\n",
       " 'kind': 545,\n",
       " 'inappropry': 546,\n",
       " 'entertain': 547,\n",
       " 'howev': 548,\n",
       " 'stay': 549,\n",
       " 'recr': 550,\n",
       " 'depart': 551,\n",
       " 'issu': 552,\n",
       " 'firm': 553,\n",
       " 'unpermit': 554,\n",
       " 'erect': 555,\n",
       " 'nud': 556,\n",
       " 'co': 557,\n",
       " 'hrb03msy0g': 558,\n",
       " 'ucyzaxztm7': 559,\n",
       " 'assocy': 560,\n",
       " 'press': 561,\n",
       " 'ap': 562,\n",
       " '2016boom': 563,\n",
       " 'ha': 564,\n",
       " 'espec': 565,\n",
       " 'slap': 566,\n",
       " 'narciss': 567,\n",
       " 'const': 568,\n",
       " 'at': 569,\n",
       " 'talk': 570,\n",
       " 'plan': 571,\n",
       " 'best': 572,\n",
       " 'pretty': 573,\n",
       " 'obvy': 574,\n",
       " 'overcompens': 575,\n",
       " 'someth': 576,\n",
       " 'seem': 577,\n",
       " 'good': 578,\n",
       " 'ide': 579,\n",
       " 'photo': 580,\n",
       " 'spend': 581,\n",
       " 'plat': 582,\n",
       " 'wow': 583,\n",
       " 'credit': 584,\n",
       " 'dalla': 585,\n",
       " 'cop': 586,\n",
       " 'slay': 587,\n",
       " 'facebook': 588,\n",
       " 'pag': 589,\n",
       " 'snip': 590,\n",
       " 'law': 591,\n",
       " 'enforc': 592,\n",
       " 'yesterday': 593,\n",
       " 'shut': 594,\n",
       " 'capt': 595,\n",
       " 'screen': 596,\n",
       " 'shoot': 597,\n",
       " 'chant': 598,\n",
       " 'bppo': 599,\n",
       " 'blackpow': 600,\n",
       " 'blackknight': 601,\n",
       " 'miss': 602,\n",
       " 'afric': 603,\n",
       " 'non': 604,\n",
       " 'control': 605,\n",
       " 'giv': 606,\n",
       " 'opportun': 607,\n",
       " 'develop': 608,\n",
       " 'patriot': 609,\n",
       " 'pro': 610,\n",
       " 'pan': 611,\n",
       " 'afr': 612,\n",
       " 'job': 613,\n",
       " 'avoid': 614,\n",
       " 'corrupt': 615,\n",
       " 'bribery': 616,\n",
       " 'exploit': 617,\n",
       " 'ail': 618,\n",
       " 'prev': 619,\n",
       " 'accompl': 620,\n",
       " 'goal': 621,\n",
       " 'work': 622,\n",
       " 'protect': 623,\n",
       " 'ag': 624,\n",
       " 'ak': 625,\n",
       " 'knight': 626,\n",
       " 'train': 627,\n",
       " 'assassin': 628,\n",
       " 'ten': 629,\n",
       " 'thousand': 630,\n",
       " 'loc': 631,\n",
       " 'eq': 632,\n",
       " 'just': 633,\n",
       " 'relentless': 634,\n",
       " 'target': 635,\n",
       " 'famy': 636,\n",
       " 'refus': 637,\n",
       " 'fin': 638,\n",
       " 'mean': 639,\n",
       " 'econom': 640,\n",
       " 'sanct': 641,\n",
       " 'destroy': 642,\n",
       " 'method': 643,\n",
       " 'western': 644,\n",
       " 'oppress': 645,\n",
       " 'exampl': 646,\n",
       " 'independ': 647,\n",
       " 'los': 648,\n",
       " 'forc': 649,\n",
       " 'someon': 650,\n",
       " 'clos': 651,\n",
       " 'eg': 652,\n",
       " 'friend': 653,\n",
       " 'etc': 654,\n",
       " 'poison': 655,\n",
       " 'cho': 656,\n",
       " 'thank': 657,\n",
       " 'amaz': 658,\n",
       " 'nick': 659,\n",
       " 'short': 660,\n",
       " 'h': 661,\n",
       " 'unprec': 662,\n",
       " 'mov': 663,\n",
       " 'detail': 664,\n",
       " 'barack': 665,\n",
       " 'hel': 666,\n",
       " 'try': 667,\n",
       " 'fig': 668,\n",
       " 'rop': 669,\n",
       " 'agree': 670,\n",
       " 'littl': 671,\n",
       " 'orang': 672,\n",
       " 'hand': 673,\n",
       " 'remain': 674,\n",
       " 'guid': 675,\n",
       " 'transit': 676,\n",
       " 'period': 677,\n",
       " 'mad': 678,\n",
       " 'sav': 679,\n",
       " 'dead': 680,\n",
       " 'monday': 681,\n",
       " 'belov': 682,\n",
       " 'command': 683,\n",
       " 'chief': 684,\n",
       " 'memo': 685,\n",
       " 'guidebook': 686,\n",
       " 'dummy': 687,\n",
       " 'docu': 688,\n",
       " 'lay': 689,\n",
       " 'spec': 690,\n",
       " 'top': 691,\n",
       " 'first': 692,\n",
       " 'ev': 693,\n",
       " 'complet': 694,\n",
       " 'unqual': 695,\n",
       " 'washington': 696,\n",
       " 'prom': 697,\n",
       " 'aggress': 698,\n",
       " 'counterter': 699,\n",
       " 'op': 700,\n",
       " 'lengthy': 701,\n",
       " 'compend': 702,\n",
       " 'policy': 703,\n",
       " '61': 704,\n",
       " 'outlin': 705,\n",
       " 'eight': 706,\n",
       " 'leg': 707,\n",
       " 'opin': 708,\n",
       " 'execut': 709,\n",
       " 'ord': 710,\n",
       " 'direct': 711,\n",
       " 'strong': 712,\n",
       " 'defens': 713,\n",
       " 'list': 714,\n",
       " 'leth': 715,\n",
       " 'dron': 716,\n",
       " 'intern': 717,\n",
       " 'undergird': 718,\n",
       " 'introduc': 719,\n",
       " 'cre': 720,\n",
       " 'reduc': 721,\n",
       " 'risk': 722,\n",
       " 'il': 723,\n",
       " 'consid': 724,\n",
       " 'observ': 725,\n",
       " 'lack': 726,\n",
       " 'emot': 727,\n",
       " 'stabl': 728,\n",
       " 'impuls': 729,\n",
       " 'er': 730,\n",
       " 'wrot': 731,\n",
       " 'hat': 732,\n",
       " 'crit': 733,\n",
       " 'much': 734,\n",
       " 'poss': 735,\n",
       " 'scrutinize': 736,\n",
       " 'account': 737,\n",
       " 'deeply': 738,\n",
       " 'car': 739,\n",
       " 'fut': 740,\n",
       " 'minim': 741,\n",
       " 'dam': 742,\n",
       " 'moron': 743,\n",
       " 'might': 744,\n",
       " 'sean': 745,\n",
       " 'gallup': 746,\n",
       " '500': 747,\n",
       " 'syr': 748,\n",
       " 'rebel': 749,\n",
       " 'fight': 750,\n",
       " 'assad': 751,\n",
       " 'infury': 752,\n",
       " 'app': 753,\n",
       " 'shock': 754,\n",
       " 'taxpay': 755,\n",
       " 'four': 756,\n",
       " 'fiv': 757,\n",
       " 'grind': 758,\n",
       " 'latest': 759,\n",
       " 'ad': 760,\n",
       " 'injury': 761,\n",
       " 'u': 762,\n",
       " 'program': 763,\n",
       " 'surrend': 764,\n",
       " 'six': 765,\n",
       " 'coalit': 766,\n",
       " 'provid': 767,\n",
       " 'truck': 768,\n",
       " 'ammunit': 769,\n",
       " 'intermedy': 770,\n",
       " 'link': 771,\n",
       " 'al': 772,\n",
       " 'qaid': 773,\n",
       " 'affy': 774,\n",
       " 'nusr': 775,\n",
       " 'front': 776,\n",
       " 'rough': 777,\n",
       " '25': 778,\n",
       " 'perc': 779,\n",
       " 'equip': 780,\n",
       " 'assign': 781,\n",
       " 'exchang': 782,\n",
       " 'saf': 783,\n",
       " 'within': 784,\n",
       " 'reg': 785,\n",
       " 'relinqu': 786,\n",
       " 'personnel': 787,\n",
       " 'air': 788,\n",
       " 'col': 789,\n",
       " 'pat': 790,\n",
       " 'ryd': 791,\n",
       " 'spokesm': 792,\n",
       " 'contradict': 793,\n",
       " 'day': 794,\n",
       " 'defect': 795,\n",
       " 'incorrect': 796,\n",
       " 'undersc': 797,\n",
       " 'persist': 798,\n",
       " 'problem': 799,\n",
       " 'effort': 800,\n",
       " 'assert': 801,\n",
       " 'wrong': 802,\n",
       " 'light': 803,\n",
       " 'ens': 804,\n",
       " 'quick': 805,\n",
       " 'dispos': 806,\n",
       " 'exact': 807,\n",
       " 'determin': 808,\n",
       " 'appropry': 809,\n",
       " 'uk': 810,\n",
       " 'dai': 811,\n",
       " 'mailh': 812,\n",
       " 'candid': 813,\n",
       " 'rand': 814,\n",
       " 'r': 815,\n",
       " 'k': 816,\n",
       " 'involv': 817,\n",
       " '45': 818,\n",
       " 'mark': 819,\n",
       " 'fan': 820,\n",
       " 'launch': 821,\n",
       " 'teen': 822,\n",
       " 'girl': 823,\n",
       " 'wisconsin': 824,\n",
       " 'ral': 825,\n",
       " 'grop': 826,\n",
       " 'support': 827,\n",
       " 'protest': 828,\n",
       " 'pep': 829,\n",
       " 'spray': 830,\n",
       " 'foot': 831,\n",
       " 'alex': 832,\n",
       " 'drak': 833,\n",
       " 'confront': 834,\n",
       " 'fifty': 835,\n",
       " 'sixty': 836,\n",
       " 'incens': 837,\n",
       " 'sex': 838,\n",
       " 'middl': 839,\n",
       " 'crowd': 840,\n",
       " 'touch': 841,\n",
       " 'ensu': 842,\n",
       " 'throw': 843,\n",
       " 'punch': 844,\n",
       " 'sep': 845,\n",
       " 'swing': 846,\n",
       " 'arm': 847,\n",
       " 'ey': 848,\n",
       " 'pul': 849,\n",
       " '15': 850,\n",
       " 'simpl': 851,\n",
       " 'yel': 852,\n",
       " 'grow': 853,\n",
       " 'fifteen': 854,\n",
       " 'proud': 855,\n",
       " 'tri': 856,\n",
       " 'hit': 857,\n",
       " 'carry': 858,\n",
       " 'soc': 859,\n",
       " 'recoil': 860,\n",
       " 'wanton': 861,\n",
       " 'janesvil': 862,\n",
       " 'shov': 863,\n",
       " 'trumpjanesvil': 864,\n",
       " 'dumptrump': 865,\n",
       " 'lt86udgbgn': 866,\n",
       " 'lady': 867,\n",
       " 'forward': 868,\n",
       " 'ladyforward': 869,\n",
       " 'march': 870,\n",
       " '29': 871,\n",
       " '2016this': 872,\n",
       " 'rememb': 873,\n",
       " 'excess': 874,\n",
       " 'bring': 875,\n",
       " 'gun': 876,\n",
       " 'kell': 877,\n",
       " 'daley': 878,\n",
       " 'combov': 879,\n",
       " 'gknkekppzu': 880,\n",
       " 'mol': 881,\n",
       " 'beck': 882,\n",
       " 'mollybeck': 883,\n",
       " '2016meanwhile': 884,\n",
       " 'remind': 885,\n",
       " 'tot': 886,\n",
       " 'david': 887,\n",
       " 'web': 888,\n",
       " 'milton': 889,\n",
       " 'wav': 890,\n",
       " 'conf': 891,\n",
       " 'flag': 892,\n",
       " 'sit': 893,\n",
       " 'symbol': 894,\n",
       " 'ankechacud': 895,\n",
       " 'rob': 896,\n",
       " 'schultz': 897,\n",
       " 'robschultzwss': 898,\n",
       " '2016the': 899,\n",
       " 'scen': 900,\n",
       " 'ring': 901,\n",
       " 'pathet': 902,\n",
       " 'intol': 903,\n",
       " 'gop': 904,\n",
       " 'descend': 905,\n",
       " 'gut': 906,\n",
       " 'depth': 907,\n",
       " 'spac': 908,\n",
       " 'cesspit': 909,\n",
       " 'rag': 910,\n",
       " 'modern': 911,\n",
       " 'screengrab': 912,\n",
       " 'lib': 913,\n",
       " 'comparison': 914,\n",
       " 'haircut': 915,\n",
       " 'naz': 916,\n",
       " 'escapad': 917,\n",
       " 'limit': 918,\n",
       " 'son': 919,\n",
       " 'sport': 920,\n",
       " 'debut': 921,\n",
       " 'hairdo': 922,\n",
       " 'hairstyl': 923,\n",
       " 'head': 924,\n",
       " 'shav': 925,\n",
       " 'fox': 926,\n",
       " 'trendy': 927,\n",
       " 'styl': 928,\n",
       " 'far': 929,\n",
       " 'unus': 930,\n",
       " 'celebr': 931,\n",
       " 'macklem': 932,\n",
       " 'beckham': 933,\n",
       " 'brad': 934,\n",
       " 'pit': 935,\n",
       " 'alt': 936,\n",
       " 'includ': 937,\n",
       " 'supremac': 938,\n",
       " 'richard': 939,\n",
       " 'wear': 940,\n",
       " 'hair': 941,\n",
       " 'begin': 942,\n",
       " 'fashy': 943,\n",
       " 'fasc': 944,\n",
       " 'screenshot': 945,\n",
       " 'internet': 946,\n",
       " 'assum': 947,\n",
       " 'worst': 948,\n",
       " 'wfberic': 949,\n",
       " 'unint': 950,\n",
       " '9mqubwenqq': 951,\n",
       " 'gharib': 952,\n",
       " 'jun': 953,\n",
       " '2017political': 954,\n",
       " 'guard': 955,\n",
       " 'word': 956,\n",
       " 'wait': 957,\n",
       " 'ben': 958,\n",
       " 'jacob': 959,\n",
       " 'bencjacob': 960,\n",
       " '2017this': 961,\n",
       " 'suggest': 962,\n",
       " 'chris': 963,\n",
       " 'bigtrix36': 964,\n",
       " 'profil': 965,\n",
       " 'ment': 966,\n",
       " 'heal': 967,\n",
       " 'counsel': 968,\n",
       " 'qdq8rpkyw5': 969,\n",
       " 'slack': 970,\n",
       " 'slack2thefuture': 971,\n",
       " 'dingb': 972,\n",
       " 'dog': 973,\n",
       " 'whistl': 974,\n",
       " 'teskcqlryh': 975,\n",
       " 'mar': 976,\n",
       " 'kreizm': 977,\n",
       " 'mariskreizm': 978,\n",
       " '26': 979,\n",
       " '2017meanwhile': 980,\n",
       " 'twerk': 981,\n",
       " 'wee': 982,\n",
       " 'smok': 983,\n",
       " 'ant': 984,\n",
       " 'virt': 985,\n",
       " 'ign': 986,\n",
       " 'rabid': 987,\n",
       " 'pict': 988,\n",
       " 'hang': 989,\n",
       " 'room': 990,\n",
       " 'hug': 991,\n",
       " 'bong': 992,\n",
       " 'stag': 993,\n",
       " 'lalapalooz': 994,\n",
       " 'chicago': 995,\n",
       " 'prid': 996,\n",
       " 'mon': 997,\n",
       " 'sieg': 998,\n",
       " 'increas': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.news_vocab._token_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4ee3bda5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{False: 0, True: 1}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.label_vocab._token_to_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751ae98d",
   "metadata": {},
   "source": [
    "## Training Routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1cc5e020",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_state(args):\n",
    "    return {'stop_early': False,\n",
    "            'early_stopping_step': 0,\n",
    "            'early_stopping_best_val': 1e8,\n",
    "            'learning_rate': args.learning_rate,\n",
    "            'epoch_index': 0,\n",
    "            'train_loss': [],\n",
    "            'train_acc': [],\n",
    "            'val_loss': [],\n",
    "            'val_acc': [],\n",
    "            'test_loss': -1,\n",
    "            'test_acc': -1,\n",
    "            'model_filename': args.model_state_file}\n",
    "\n",
    "\n",
    "def update_train_state(args, model, train_state):\n",
    "    \"\"\"Handle the training state updates.\n",
    "\n",
    "    Components:\n",
    "     - Early Stopping: Prevent overfitting.\n",
    "     - Model Checkpoint: Model is saved if the model is better\n",
    "    \n",
    "    :param args: main arguments\n",
    "    :param model: model to train\n",
    "    :param train_state: a dictionary representing the training state values\n",
    "    :returns:\n",
    "        a new train_state\n",
    "    \"\"\"\n",
    "\n",
    "    # Save one model at least\n",
    "    if train_state['epoch_index'] == 0:\n",
    "        torch.save(model.state_dict(), train_state['model_filename'])\n",
    "        train_state['stop_early'] = False\n",
    "\n",
    "    # Save model if performance improved\n",
    "    elif train_state['epoch_index'] >= 1:\n",
    "        loss_tm1, loss_t = train_state['val_loss'][-2:]\n",
    "         \n",
    "        # If loss worsened\n",
    "        #if loss_t >= loss_tm1: # if current loss becomes smaller than the previous loss, early_stopping_step is reset to 0.\n",
    "                                # this statement makes the model training time longer, compared to the statement below. \n",
    "        if loss_t >= train_state['early_stopping_best_val']:  # curent loss is compared with early_stopping_best_val loss value\n",
    "            # Update step\n",
    "            train_state['early_stopping_step'] += 1\n",
    "        # Loss decreased\n",
    "        else:\n",
    "            # Save the best model\n",
    "            if loss_t < train_state['early_stopping_best_val']:\n",
    "                torch.save(model.state_dict(), train_state['model_filename'])\n",
    "                train_state['early_stopping_best_val'] = loss_t\n",
    "\n",
    "            # Reset early stopping step\n",
    "            train_state['early_stopping_step'] = 0\n",
    "\n",
    "        # Stop early ?\n",
    "        train_state['stop_early'] = \\\n",
    "            train_state['early_stopping_step'] >= args.early_stopping_criteria\n",
    "\n",
    "    return train_state\n",
    "\n",
    "\n",
    "def compute_accuracy(y_pred, y_target, threshold=0.5):\n",
    "\n",
    "    \"\"\"Compute accuracy for binary classification\"\"\"\n",
    "\n",
    "    # Convert predictions to probabilities using sigmoid\n",
    "    y_prob = torch.sigmoid(y_pred)\n",
    "    # Convert probabilities to binary predictions\n",
    "    y_pred_class = (y_prob > threshold).float()\n",
    "    # Ensure targets are float for comparison\n",
    "    y_target_float = y_target.float()\n",
    "    # Calculate accuracy\n",
    "    correct = (y_pred_class == y_target_float).sum().item()\n",
    "    total = y_target_float.size(0)\n",
    "    return correct / total * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "35b5f774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset info:\n",
      "  Train size: 31427\n",
      "  Val size: 6734\n",
      "  Test size: 6737\n",
      "  Max sequence length: 512\n",
      "  Batch size: 64\n",
      "  Train batches: 491\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aea08212fcc474985f5559018c7906a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training routine:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "219c547446ff45829ed03151e825d490",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "split=train:   0%|          | 0/491 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5d7662bfd6a4c399734a8e616aa94dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "split=val:   0%|          | 0/105 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifier = classifier.to(args.device)\n",
    "dataset.class_weights = dataset.class_weights.to(args.device)\n",
    "    \n",
    "loss_func = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=args.learning_rate)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, mode='min', factor=0.1, patience=10)\n",
    "\n",
    "train_state = make_train_state(args)\n",
    "\n",
    "# Print dataset info for debugging\n",
    "print(f\"Dataset info:\")\n",
    "print(f\"  Train size: {dataset.train_size}\")\n",
    "print(f\"  Val size: {dataset.validation_size}\")\n",
    "print(f\"  Test size: {dataset.test_size}\")\n",
    "print(f\"  Max sequence length: {dataset._max_seq_length}\")\n",
    "print(f\"  Batch size: {args.batch_size}\")\n",
    "print(f\"  Train batches: {dataset.get_num_batches(args.batch_size)}\")\n",
    "\n",
    "epoch_bar = tqdm(desc='training routine', total=args.num_epochs, position=0)\n",
    "\n",
    "dataset.set_split('train')\n",
    "train_bar = tqdm(desc='split=train', total=dataset.get_num_batches(args.batch_size), position=1, leave=True)\n",
    "\n",
    "dataset.set_split('val')\n",
    "val_bar = tqdm(desc='split=val', total=dataset.get_num_batches(args.batch_size), position=1, leave=True)\n",
    "\n",
    "try:\n",
    "\n",
    "    for epoch_index in range(args.num_epochs):\n",
    "        train_state['epoch_index'] = epoch_index\n",
    "\n",
    "        # Iterate over training dataset\n",
    "\n",
    "        # setup: batch generator, set loss and acc to 0, set train mode on\n",
    "        dataset.set_split('train')\n",
    "        batch_generator = generate_batches(dataset, \n",
    "                                           batch_size=args.batch_size, \n",
    "                                           device=args.device)\n",
    "        running_loss = 0.0\n",
    "        running_acc = 0.0\n",
    "        classifier.train()\n",
    "\n",
    "        for batch_index, batch_dict in enumerate(batch_generator):\n",
    "            # the training routine is these 5 steps:\n",
    "\n",
    "            # --------------------------------------    \n",
    "            # step 1. zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # step 2. compute the output\n",
    "            y_pred = classifier(x_in=batch_dict['x_data'], \n",
    "                        x_lengths=batch_dict['x_length'])\n",
    "\n",
    "            # 2. 修正 Target 形状并计算 Loss (使用前面建议的修正)\n",
    "            y_target = batch_dict['y_target'].float().unsqueeze(1) \n",
    "            loss = loss_func(y_pred, y_target) \n",
    "    \n",
    "            running_loss += (loss.item() - running_loss) / (batch_index + 1)\n",
    "\n",
    "            # step 4. use loss to produce gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # step 5. use optimizer to take gradient step\n",
    "            optimizer.step()\n",
    "            # -----------------------------------------\n",
    "            # compute the accuracy\n",
    "            acc_t = compute_accuracy(y_pred, y_target)\n",
    "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "\n",
    "            # update bar\n",
    "            train_bar.set_postfix(loss=running_loss, acc=running_acc, epoch=epoch_index)\n",
    "            train_bar.update()\n",
    "\n",
    "        train_state['train_loss'].append(running_loss)\n",
    "        train_state['train_acc'].append(running_acc)\n",
    "\n",
    "        # Iterate over val dataset\n",
    "\n",
    "        # setup: batch generator, set loss and acc to 0; set eval mode on\n",
    "\n",
    "        dataset.set_split('val')\n",
    "        batch_generator = generate_batches(dataset, \n",
    "                                           batch_size=args.batch_size, \n",
    "                                           device=args.device)\n",
    "        running_loss = 0.\n",
    "        running_acc = 0.\n",
    "        classifier.eval()\n",
    "\n",
    "        with torch.no_grad():  # Disable gradient computation\n",
    "          for batch_index, batch_dict in enumerate(batch_generator):\n",
    "            # compute the output\n",
    "            y_pred = classifier(x_in=batch_dict['x_data'], \n",
    "                        x_lengths=batch_dict['x_length'])\n",
    "\n",
    "            # 2. 修正 Target 形状并计算 Loss (使用前面建议的修正)\n",
    "            y_target = batch_dict['y_target'].float().unsqueeze(1) \n",
    "            loss = loss_func(y_pred, y_target) \n",
    "            running_loss += (loss.item() - running_loss) / (batch_index + 1)\n",
    "\n",
    "            # compute the accuracy\n",
    "            acc_t = compute_accuracy(y_pred, y_target)\n",
    "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "            val_bar.set_postfix(loss=running_loss, acc=running_acc, epoch=epoch_index)\n",
    "            val_bar.update()\n",
    "\n",
    "        train_state['val_loss'].append(running_loss)\n",
    "        train_state['val_acc'].append(running_acc)\n",
    "\n",
    "        train_state = update_train_state(args=args, model=classifier, \n",
    "                                         train_state=train_state)\n",
    "\n",
    "        scheduler.step(train_state['val_loss'][-1])\n",
    "\n",
    "        train_bar.reset()\n",
    "        val_bar.reset()\n",
    "        epoch_bar.update()\n",
    "\n",
    "        if train_state['stop_early']:\n",
    "            break\n",
    "            \n",
    "except KeyboardInterrupt:\n",
    "    print(\"Exiting loop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "71a00e5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "line": {
          "color": "blue"
         },
         "mode": "lines+markers",
         "name": "Training Loss",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13
         ],
         "y": [
          0.11798998586479725,
          0.021909035780218623,
          0.02076202739990844,
          0.013553949973693918,
          0.00784500672387352,
          0.005419198113736407,
          0.0032725679008231505,
          0.001712817739379496,
          0.0011597074144502671,
          0.004785551911378161,
          0.0047193527007076035,
          0.0011669927052583306,
          0.0010057626513266733
         ]
        },
        {
         "line": {
          "color": "royalblue"
         },
         "mode": "lines",
         "name": "Validation Loss",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13
         ],
         "y": [
          0.029277218698656987,
          0.023455514927350325,
          0.016009420139848123,
          0.014640908624278382,
          0.014416230231983634,
          0.011686507044318464,
          0.012968315381260169,
          0.01105055094327933,
          0.01377406709547185,
          0.016239235775130853,
          0.015185904591202242,
          0.01426899708549172,
          0.017171157270920615
         ]
        }
       ],
       "layout": {
        "legend": {
         "x": 0.02,
         "y": 0.98
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Training and Validation Loss"
        },
        "xaxis": {
         "title": {
          "text": "Epochs"
         }
        },
        "yaxis": {
         "title": {
          "text": "Loss"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "acc = train_state['train_acc']\n",
    "val_acc = train_state['val_acc']\n",
    "loss = train_state['train_loss']\n",
    "val_loss = train_state['val_loss']\n",
    "\n",
    "epochs = list(range(1, len(acc) + 1))\n",
    "\n",
    "# Create interactive line chart\n",
    "fig = go.Figure()\n",
    "\n",
    "for y, name, color, mode in [(loss, 'Training Loss', 'blue', 'lines+markers'),\n",
    "                             (val_loss, 'Validation Loss', 'royalblue', 'lines')]:\n",
    "    fig.add_trace(go.Scatter(x=epochs, y=y, mode=mode, name=name, line=dict(color=color)))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Training and Validation Loss',\n",
    "    xaxis_title='Epochs',\n",
    "    yaxis_title='Loss',\n",
    "    legend=dict(x=0.02, y=0.98)\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "090bc59c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "line": {
          "color": "blue"
         },
         "mode": "lines+markers",
         "name": "Training Accuracy",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13
         ],
         "y": [
          95.71028513238281,
          99.49083503054989,
          99.5067464358452,
          99.62449083503049,
          99.80269857433811,
          99.81860997963341,
          99.90134928716898,
          99.9586303462322,
          99.97454175152748,
          99.88543788187378,
          99.8727087576375,
          99.97135947046846,
          99.97454175152751
         ]
        },
        {
         "line": {
          "color": "royalblue"
         },
         "mode": "lines",
         "name": "Validation Accuracy",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13
         ],
         "y": [
          99.38988095238098,
          99.43452380952384,
          99.61309523809524,
          99.62797619047622,
          99.6428571428572,
          99.702380952381,
          99.73214285714285,
          99.77678571428575,
          99.68750000000003,
          99.64285714285715,
          99.6875,
          99.71726190476193,
          99.74702380952381
         ]
        }
       ],
       "layout": {
        "legend": {
         "x": 0.02,
         "y": 0.98
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Training and Validation Accuracy"
        },
        "xaxis": {
         "title": {
          "text": "Epochs"
         }
        },
        "yaxis": {
         "title": {
          "text": "Accuracy"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create interactive line chart for accuracy\n",
    "fig = go.Figure()\n",
    "\n",
    "for y, name, color, mode in [(acc, 'Training Accuracy', 'blue', 'lines+markers'),\n",
    "                             (val_acc, 'Validation Accuracy', 'royalblue', 'lines')]:\n",
    "    fig.add_trace(go.Scatter(x=epochs, y=y, mode=mode, name=name, line=dict(color=color)))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Training and Validation Accuracy',\n",
    "    xaxis_title='Epochs',\n",
    "    yaxis_title='Accuracy',\n",
    "    legend=dict(x=0.02, y=0.98)\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "df9016d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the loss & accuracy on the test set using the best available model\n",
    "\n",
    "classifier.load_state_dict(torch.load(train_state['model_filename'],weights_only=False))\n",
    "\n",
    "classifier = classifier.to(args.device)\n",
    "dataset.class_weights = dataset.class_weights.to(args.device)\n",
    "loss_func = nn.BCEWithLogitsLoss()\n",
    "\n",
    "dataset.set_split('test')\n",
    "batch_generator = generate_batches(dataset, \n",
    "                                   batch_size=args.batch_size, \n",
    "                                   device=args.device)\n",
    "running_loss = 0.\n",
    "running_acc = 0.\n",
    "classifier.eval()\n",
    "\n",
    "y_pred_list = []         # store predicted values for confusion matrix\n",
    "y_true_list = []        # ground truth values\n",
    "\n",
    "with torch.no_grad():  # Disable gradient computation\n",
    "  for batch_index, batch_dict in enumerate(batch_generator):\n",
    "    # compute the output\n",
    "    y_pred =  classifier(batch_dict['x_data'],\n",
    "                         x_lengths=batch_dict['x_length'])\n",
    "\n",
    "    # store predicted values and ground truth values for calculating confusion matrix\n",
    "    y_pred_prob = torch.sigmoid(y_pred).squeeze()\n",
    "    y_pred_binary = (y_pred_prob > 0.5).float()\n",
    "    y_pred_list.extend(y_pred_binary.cpu().numpy())\n",
    "    y_target = batch_dict['y_target'].float().unsqueeze(1)\n",
    "    y_true_list.extend(y_target.cpu().numpy())\n",
    "    \n",
    "    # compute the loss\n",
    "    loss = loss_func(y_pred, y_target) \n",
    "    loss_t = loss.item()\n",
    "    running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
    "\n",
    "    # compute the accuracy\n",
    "    acc_t = compute_accuracy(y_pred, y_target)\n",
    "    running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "\n",
    "train_state['test_loss'] = running_loss\n",
    "train_state['test_acc'] = running_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5529f5c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.014516954756583707;\n",
      "Test Accuracy: 99.74702380952381\n"
     ]
    }
   ],
   "source": [
    "print(\"Test loss: {};\".format(train_state['test_loss']))\n",
    "print(\"Test Accuracy: {}\".format(train_state['test_acc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4e6cb036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary classes: ['False', 'True']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "# For binary classification, we have two classes: False (0) and True (1)\n",
    "binary_classes = ['False', 'True']\n",
    "print(\"Binary classes:\", binary_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4031ead5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True       False  True\n",
      "Predicted             \n",
      "False       3506     7\n",
      "True          10  3197\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "cm = confusion_matrix(y_true_list, y_pred_list)\n",
    "cm_df = pd.DataFrame(cm.T, index=binary_classes, columns=binary_classes)\n",
    "cm_df.index.name = 'Predicted'\n",
    "cm_df.columns.name = 'True'\n",
    "print(cm_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ff9fb44c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      1.00      1.00      3516\n",
      "        True       1.00      1.00      1.00      3204\n",
      "\n",
      "    accuracy                           1.00      6720\n",
      "   macro avg       1.00      1.00      1.00      6720\n",
      "weighted avg       1.00      1.00      1.00      6720\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true_list, y_pred_list, target_names=binary_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eaead303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "class_names = ['fake', 'real']\n",
    "name = 'CNN Model'\n",
    "cm = confusion_matrix(y_true_list, y_pred_list)\n",
    "plt.figure(figsize=(15, 10))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title(f'{name} confusion_matrix', fontsize=12)\n",
    "plt.ylabel('True Label', fontsize=10)\n",
    "plt.xlabel('Predicted Label', fontsize=10)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
