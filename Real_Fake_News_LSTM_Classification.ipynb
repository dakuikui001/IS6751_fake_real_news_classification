{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a96bae1",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef6d6359",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata  \n",
    "import inflect       \n",
    "import re\n",
    "from nltk import sent_tokenize\n",
    "from nltk.stem import LancasterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.util import ngrams\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ad5027",
   "metadata": {},
   "source": [
    "## Step 1: Text pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413c6f05",
   "metadata": {},
   "source": [
    "### 1.1 Text Combination and Train_valid_test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a3bfdad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44898, 5)\n",
      "Index(['title', 'text', 'subject', 'date', 'label'], dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 44898 entries, 0 to 44897\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   title    44898 non-null  object\n",
      " 1   text     44898 non-null  object\n",
      " 2   subject  44898 non-null  object\n",
      " 3   date     44898 non-null  object\n",
      " 4   label    44898 non-null  object\n",
      "dtypes: object(5)\n",
      "memory usage: 1.7+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "fake_news_df = pd.read_csv('Data/Fake.csv')\n",
    "true_news_df = pd.read_csv('Data/True.csv')\n",
    "fake_news_df['label'] = 'False'\n",
    "true_news_df['label'] = 'True'\n",
    "news_df = pd.concat([fake_news_df, true_news_df], ignore_index=True, axis=0)\n",
    "print(news_df.shape)\n",
    "print(news_df.columns)\n",
    "print(news_df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a15ec14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44898, 5)\n"
     ]
    }
   ],
   "source": [
    "news_df = news_df[news_df.text.isna() == False]\n",
    "news_df = news_df[news_df.title.isna() == False]\n",
    "news_df = news_df[news_df.subject.isna() == False]\n",
    "print(news_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "066de764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  label\n",
      "0   Donald Trump Sends Out Embarrassing New Year’...  False\n",
      "1   Drunk Bragging Trump Staffer Started Russian ...  False\n",
      "2   Sheriff David Clarke Becomes An Internet Joke...  False\n",
      "3   Trump Is So Obsessed He Even Has Obama’s Name...  False\n",
      "4   Pope Francis Just Called Out Donald Trump Dur...  False\n",
      "label\n",
      "False    23481\n",
      "True     21417\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "news_df['text'] = news_df['title'] + ' ' + news_df['text'] + ' ' + news_df['subject']\n",
    "news_df.drop(['title', 'date', 'subject'], axis=1, inplace=True)\n",
    "print(news_df.head())\n",
    "print(news_df.label.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5005029",
   "metadata": {},
   "outputs": [],
   "source": [
    "by_labels = collections.defaultdict(list)\n",
    "for _, row in news_df.iterrows():\n",
    "    by_labels[row.label].append(row.to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bff5665f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dateset to train, validate and test dataset and stored in list\n",
    "final_list = []\n",
    "np.random.seed(1234)\n",
    "\n",
    "for _, item_list in sorted(by_labels.items()):\n",
    "\n",
    "    np.random.shuffle(item_list)\n",
    "    \n",
    "    n_total = len(item_list)\n",
    "    n_train = int(0.7 * n_total)\n",
    "    n_valid = int(0.15 * n_total)\n",
    "    n_test = n_total - n_train - n_valid\n",
    "    \n",
    "    # Give data point a split attribute\n",
    "    for item in item_list[:n_train]:\n",
    "        item['split'] = 'train'\n",
    "    for item in item_list[n_train:n_train+n_valid]:\n",
    "        item['split'] = 'val'\n",
    "    for item in item_list[n_train+n_valid:]:\n",
    "        item['split'] = 'test'\n",
    "\n",
    "    # Add to final list\n",
    "    final_list.extend(item_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac8d65ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "split\n",
       "train    31427\n",
       "test      6737\n",
       "val       6734\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = pd.DataFrame(final_list)\n",
    "final_df.split.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50c9fc3",
   "metadata": {},
   "source": [
    "### 1.2 Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15f36896",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(words):\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word not in stopwords.words('english'):\n",
    "            new_words.append(word)\n",
    "    return new_words\n",
    "\n",
    "def stem_words(words):\n",
    "    stemmer = LancasterStemmer()\n",
    "    stems = []\n",
    "    for word in words:\n",
    "        stem = stemmer.stem(word)\n",
    "        stems.append(stem)\n",
    "    return stems\n",
    "\n",
    "def lemmatize_verbs(words):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmas = []\n",
    "    for word in words:\n",
    "        lemma = lemmatizer.lemmatize(word, pos='v')\n",
    "        lemmas.append(lemma)\n",
    "    return lemmas\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    if type(text) == float:\n",
    "        print(text)\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"([.,!?])\", r\" \\1 \", text)  # E.g., convert \"end.\" to \"end . \" ; \\1 indicates a matched character\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]+\", r\" \", text) # replace special characters with empty string\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26b99ce8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jake tapper burns trump with bill maher he is ...</td>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>buried by media aide to leftist us congressman...</td>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cnn clown who cries about fake news uses unver...</td>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>delusional obama on how divided america has be...</td>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>veterans cozy trump relationship with russian ...</td>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  split\n",
       "0  jake tapper burns trump with bill maher he is ...  False  train\n",
       "1  buried by media aide to leftist us congressman...  False  train\n",
       "2  cnn clown who cries about fake news uses unver...  False  train\n",
       "3  delusional obama on how divided america has be...  False  train\n",
       "4  veterans cozy trump relationship with russian ...  False  train"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df['text'] = final_df['text'].apply(preprocess_text)\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34e6021a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[jake, tapper, burns, trump, with, bill, maher...</td>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[buried, by, media, aide, to, leftist, us, con...</td>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[cnn, clown, who, cries, about, fake, news, us...</td>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[delusional, obama, on, how, divided, america,...</td>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[veterans, cozy, trump, relationship, with, ru...</td>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  split\n",
       "0  [jake, tapper, burns, trump, with, bill, maher...  False  train\n",
       "1  [buried, by, media, aide, to, leftist, us, con...  False  train\n",
       "2  [cnn, clown, who, cries, about, fake, news, us...  False  train\n",
       "3  [delusional, obama, on, how, divided, america,...  False  train\n",
       "4  [veterans, cozy, trump, relationship, with, ru...  False  train"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df['text'] = final_df['text'].apply(word_tokenize)\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b7291a",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['text'] = final_df['text'].apply(remove_stopwords)\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a431b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['text'] = final_df['text'].apply(stem_words)\n",
    "final_df['text'] = final_df['text'].apply(lemmatize_verbs)\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a53eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('Data/preprocessed_news.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0334fea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "430.4274577932202"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df['word_length'] = final_df['text'].apply(lambda x: len(x.split()))\n",
    "final_df['word_length'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484337be",
   "metadata": {},
   "source": [
    "# LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924c23b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "import os\n",
    "import json\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b95a328",
   "metadata": {},
   "source": [
    "## Vocabulary, Vectorizer, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3072f4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary(object):\n",
    "    \"\"\"Class to process text and extract vocabulary for mapping\"\"\"\n",
    "\n",
    "    def __init__(self, token_to_idx=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            token_to_idx (dict): a pre-existing map of tokens to indices\n",
    "        \"\"\"    \n",
    "\n",
    "        if token_to_idx is None:\n",
    "            token_to_idx = {}\n",
    "        self._token_to_idx = token_to_idx         \n",
    "                                                  \n",
    "        self._idx_to_token = {idx: token \n",
    "                              for token, idx in self._token_to_idx.items()}\n",
    "        \n",
    "    def add_token(self, token):\n",
    "        \"\"\"Update mapping dicts based on the token.\n",
    "\n",
    "        Args:\n",
    "            token (str): the item to add into the Vocabulary\n",
    "        Returns:\n",
    "            index (int): the integer corresponding to the token\n",
    "        \"\"\"\n",
    "        if token in self._token_to_idx:\n",
    "            index = self._token_to_idx[token]\n",
    "        else:\n",
    "            index = len(self._token_to_idx)\n",
    "            self._token_to_idx[token] = index\n",
    "            self._idx_to_token[index] = token\n",
    "        return index\n",
    "            \n",
    "    def lookup_token(self, token):\n",
    "        \"\"\"Retrieve the index associated with the token \n",
    "        \n",
    "        Args:\n",
    "            token (str): the token to look up \n",
    "        Returns:\n",
    "            index (int): the index corresponding to the token\n",
    "        \"\"\"\n",
    "        return self._token_to_idx[token]\n",
    "\n",
    "    def lookup_index(self, index):\n",
    "        \"\"\"Return the token associated with the index\n",
    "        \n",
    "        Args: \n",
    "            index (int): the index to look up\n",
    "        Returns:\n",
    "            token (str): the token corresponding to the index\n",
    "        Raises:\n",
    "            KeyError: if the index is not in the Vocabulary\n",
    "        \"\"\"\n",
    "        if index not in self._idx_to_token:\n",
    "            raise KeyError(\"the index (%d) is not in the Vocabulary\" % index)\n",
    "        return self._idx_to_token[index]\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"<Vocabulary(size=%d)>\" % len(self)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._token_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3e5d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsVocabulary(Vocabulary):\n",
    "    def __init__(self, token_to_idx=None, unk_token=\"<UNK>\",\n",
    "                 mask_token=\"<MASK>\", begin_seq_token=\"<BEGIN>\",\n",
    "                 end_seq_token=\"<END>\"):\n",
    "\n",
    "        super(NewsVocabulary, self).__init__(token_to_idx)\n",
    "\n",
    "        self._mask_token = mask_token  # for paddding, e.g., 'McMahan' -> [2, 5, 6, 5, 7, 8, 7, 9, 3, 0, 0, 0, ..., 0]\n",
    "        self._unk_token = unk_token\n",
    "        self._begin_seq_token = begin_seq_token\n",
    "        self._end_seq_token = end_seq_token\n",
    "\n",
    "        self.mask_index = self.add_token(self._mask_token)           # mask_index is 0\n",
    "        self.unk_index = self.add_token(self._unk_token)             # unk_index is 1\n",
    "        self.begin_seq_index = self.add_token(self._begin_seq_token) # begin_seq_index is 2\n",
    "        self.end_seq_index = self.add_token(self._end_seq_token)     # end_seq_index is 3\n",
    "\n",
    "    def lookup_token(self, token):\n",
    "        \"\"\"Retrieve the index associated with the token \n",
    "          or the UNK index if token isn't present.\n",
    "        \n",
    "        Args:\n",
    "            token (str): the token to look up \n",
    "        Returns:\n",
    "            index (int): the index corresponding to the token\n",
    "        Notes:\n",
    "            `unk_index` needs to be >=0 (having been added into the Vocabulary) \n",
    "              for the UNK functionality \n",
    "        \"\"\"\n",
    "        if self.unk_index >= 0:\n",
    "            return self._token_to_idx.get(token, self.unk_index)\n",
    "        else:\n",
    "            return self._token_to_idx[token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372c6569",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsVectorizer(object):\n",
    "    \"\"\" The Vectorizer which coordinates the Vocabularies and puts them to use\"\"\"   \n",
    "    def __init__(self, news_vocab, label_vocab):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            news_vocab (NewsVocabulary): maps words to integers\n",
    "            label_vocab (Vocabulary): maps labels to integers\n",
    "        \"\"\"\n",
    "        self.news_vocab = news_vocab\n",
    "        self.label_vocab = label_vocab\n",
    "\n",
    "    def vectorize(self, news, vector_length=-1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            news (str): the string of words\n",
    "            vector_length (int): an argument for forcing the length of index vector\n",
    "        \"\"\"        \n",
    "        # Split text into words and limit the number of words\n",
    "        words = str(news).split(\" \")\n",
    "        \n",
    "        # If vector_length is specified and positive, truncate words to fit\n",
    "        if vector_length > 0:\n",
    "            max_words = vector_length - 2  # Reserve space for begin and end tokens\n",
    "            words = words[:max_words]\n",
    "        \n",
    "        indices = [self.news_vocab.begin_seq_index]\n",
    "        indices.extend(self.news_vocab.lookup_token(token) \n",
    "                       for token in words)\n",
    "        indices.append(self.news_vocab.end_seq_index)\n",
    "\n",
    "        if vector_length < 0:\n",
    "            vector_length = len(indices)\n",
    "\n",
    "        out_vector = np.zeros(vector_length, dtype=np.int64)   # Fixed size vector\n",
    "        out_vector[:len(indices)] = indices\n",
    "        out_vector[len(indices):] = self.news_vocab.mask_index\n",
    "        \n",
    "        return out_vector, len(indices)\n",
    "\n",
    "    @classmethod\n",
    "    def from_dataframe(cls, news_df):\n",
    "        \"\"\"Instantiate the vectorizer from the dataset dataframe\n",
    "        \n",
    "        Args:\n",
    "            news_df (pandas.DataFrame): the news dataset\n",
    "        Returns:\n",
    "            an instance of the NewsVectorizer\n",
    "        \"\"\"\n",
    "        news_vocab = NewsVocabulary() # add mask, unknown, begin_seq, and end_seq tokens to the token_to_index dictionary\n",
    "        label_vocab = Vocabulary()\n",
    "        \n",
    "        for index, row in news_df.iterrows():\n",
    "            for word in str(row.text).split(\" \"):\n",
    "                news_vocab.add_token(word)\n",
    "            label_vocab.add_token(row.label)\n",
    "\n",
    "        return cls(news_vocab, label_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8498c6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsDataset(Dataset):\n",
    "    def __init__(self, news_df, vectorizer, max_seq_length=512):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            news_df (pandas.DataFrame): the dataset\n",
    "            vectorizer (NewsVectorizer): vectorizer instatiated from dataset\n",
    "            max_seq_length (int): maximum sequence length to prevent memory issues\n",
    "        \"\"\"\n",
    "        self.news_df = news_df \n",
    "        self._vectorizer = vectorizer\n",
    "\n",
    "        # Use the specified max_seq_length directly\n",
    "        self._max_seq_length = max_seq_length\n",
    "\n",
    "        self.train_df = self.news_df[self.news_df.split=='train']\n",
    "        self.train_size = len(self.train_df)\n",
    "\n",
    "        self.val_df = self.news_df[self.news_df.split=='val']\n",
    "        self.validation_size = len(self.val_df)\n",
    "\n",
    "        self.test_df = self.news_df[self.news_df.split=='test']\n",
    "        self.test_size = len(self.test_df)\n",
    "\n",
    "        self._lookup_dict = {'train': (self.train_df, self.train_size), \n",
    "                             'val': (self.val_df, self.validation_size), \n",
    "                             'test': (self.test_df, self.test_size)}\n",
    "\n",
    "        self.set_split('train')\n",
    "        \n",
    "        # Class weights for binary classification\n",
    "        class_counts = self.train_df.label.value_counts().to_dict()   # {'False': count1, 'True': count2}\n",
    "        def sort_key(item):\n",
    "            return self._vectorizer.label_vocab.lookup_token(item[0]) # e.g, index of False is 0, True is 1\n",
    "        sorted_counts = sorted(class_counts.items(), key=sort_key)          # sort by the index number of label_vocab\n",
    "                                   # {('False', count1), ('True', count2)}\n",
    "        frequencies = [count for _, count in sorted_counts]\n",
    "        self.class_weights = 1.0 / torch.tensor(frequencies, dtype=torch.float32) # [1/count1, 1/count2]\n",
    "\n",
    "        \n",
    "    @classmethod\n",
    "    def load_dataset_and_make_vectorizer(cls, news_csv, max_seq_length=512):\n",
    "        \"\"\"Load dataset and make a new vectorizer from scratch\n",
    "        \n",
    "        Args:\n",
    "            news_csv (str): location of the dataset\n",
    "            max_seq_length (int): maximum sequence length to prevent memory issues\n",
    "        Returns:\n",
    "            an instance of NewsDataset\n",
    "        \"\"\"\n",
    "        news_df = pd.read_csv(news_csv)\n",
    "        train_news_df = news_df[news_df.split=='train']\n",
    "        return cls(news_df, NewsVectorizer.from_dataframe(train_news_df), max_seq_length)\n",
    "        \n",
    "    def get_vectorizer(self):\n",
    "        \"\"\" returns the vectorizer \"\"\"\n",
    "        return self._vectorizer\n",
    "\n",
    "    def set_split(self, split=\"train\"):\n",
    "        self._target_split = split\n",
    "        self._target_df, self._target_size = self._lookup_dict[split]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._target_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"the primary entry point method for PyTorch datasets\n",
    "        \n",
    "        Args:\n",
    "            index (int): the index to the data point \n",
    "        Returns:\n",
    "            a dictionary holding the data point's:\n",
    "                features (x_data)\n",
    "                label (y_target)\n",
    "                feature length (x_length)\n",
    "        \"\"\"\n",
    "        row = self._target_df.iloc[index]\n",
    "        \n",
    "        news_vector, vec_length = \\\n",
    "            self._vectorizer.vectorize(row.text, self._max_seq_length)\n",
    "        \n",
    "        label_index = \\\n",
    "            self._vectorizer.label_vocab.lookup_token(row.label)\n",
    "\n",
    "        return {'x_data': news_vector,      # 'x_data': [2, 5, 6, 5, 7, 8, 7, 9, 3, 0, 0, 0, ..., 0] when news is processed\n",
    "                'y_target': label_index, # 'y_target': 0 for False, 1 for True              \n",
    "                'x_length': vec_length}        # 'x_length': sequence length\n",
    "    \n",
    "    def get_num_batches(self, batch_size):\n",
    "        \"\"\"Given a batch size, return the number of batches in the dataset\n",
    "        \n",
    "        Args:\n",
    "            batch_size (int)\n",
    "        Returns:\n",
    "            number of batches in the dataset\n",
    "        \"\"\"\n",
    "        return len(self) // batch_size   \n",
    "\n",
    "def generate_batches(dataset, batch_size, shuffle=True,\n",
    "                     drop_last=True, device=\"cpu\"): \n",
    "    \"\"\"\n",
    "    A generator function which wraps the PyTorch DataLoader. It will \n",
    "      ensure each tensor is on the write device location.\n",
    "    \"\"\"\n",
    "    dataloader = DataLoader(dataset=dataset, batch_size=batch_size,\n",
    "                            shuffle=shuffle, drop_last=drop_last)\n",
    "\n",
    "    for data_dict in dataloader:\n",
    "        out_data_dict = {}\n",
    "        for name, tensor in data_dict.items():\n",
    "            out_data_dict[name] = data_dict[name].to(device)\n",
    "        yield out_data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db06ac7",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a15844",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def column_gather(y_out, x_lengths):\n",
    "    '''Get a specific vector from each batch datapoint in `y_out`.\n",
    "\n",
    "    More precisely, iterate over batch row indices, get the vector that's at\n",
    "    the position indicated by the corresponding value in `x_lengths` at the row\n",
    "    index.\n",
    "\n",
    "    Args:\n",
    "        y_out (torch.FloatTensor, torch.cuda.FloatTensor)\n",
    "            shape: (batch, sequence, feature)\n",
    "        x_lengths (torch.LongTensor, torch.cuda.LongTensor)\n",
    "            shape: (batch,)\n",
    "\n",
    "    Returns:\n",
    "        y_out (torch.FloatTensor, torch.cuda.FloatTensor)\n",
    "            shape: (batch, feature)\n",
    "    '''\n",
    "    x_lengths = x_lengths.long().detach().cpu().numpy() - 1   # deduct 1 since the index starts from 0\n",
    "                                                              # e.g., [9, 6, 11, 9, 7, ...., 12]\n",
    "    out = []\n",
    "    for batch_index, column_index in enumerate(x_lengths): # out gets the last hidden vector of each input: (batch, hidden_size)\n",
    "        out.append(y_out[batch_index, column_index]) # e.g., y_out[0, 9], y_out[1, 6]\n",
    "\n",
    "    return torch.stack(out)  # (batch, hidden_size*num_directions); E.g., (64, 64*num_direction)\n",
    "\n",
    "def column_summation(y_out, x_lengths, mode=\"mean\"):\n",
    "    '''Get a max or mean vector from each batch datapoint in `y_out`.\n",
    "\n",
    "    More precisely, iterate over batch row indices, get the max or mean vector of all the vectors by \n",
    "    the position indicated by the corresponding value in `x_lengths` at the row index.\n",
    "\n",
    "    Args:\n",
    "        y_out (torch.FloatTensor, torch.cuda.FloatTensor)\n",
    "            shape: (batch, sequence, feature)\n",
    "        x_lengths (torch.LongTensor, torch.cuda.LongTensor)\n",
    "            shape: (batch,)\n",
    "        mode: \"mean\" for mean vector; \"max\" for max vector\n",
    "\n",
    "    Returns:\n",
    "        y_out (torch.FloatTensor, torch.cuda.FloatTensor)\n",
    "            shape: (batch, feature)\n",
    "    '''\n",
    "    x_lengths = x_lengths.long().detach().cpu().numpy() - 1\n",
    "\n",
    "    out = []\n",
    "    for batch_index, column_index in enumerate(x_lengths):\n",
    "        if mode == \"mean\":\n",
    "            # replace \"pass\" with your code to get the mean vector of current batch item from y_out[], and append it to out list.\n",
    "            out.append(y_out[batch_index, :column_index + 1].mean(dim=0))\n",
    "        else:      # mode == \"max\"\n",
    "            # replace \"pass\" with your code to get the max vector of current batch item from y_out[], , and append it to out list.\n",
    "            out.append(y_out[batch_index, :column_index + 1].max(dim=0).values)\n",
    "\n",
    "    return torch.stack(out)\n",
    "\n",
    "class NewsClassifier(nn.Module):\n",
    "    \"\"\" A Classifier with an RNN to extract features and an MLP to classify \"\"\"\n",
    "    def __init__(self, embedding_size, num_embeddings, num_classes,\n",
    "                 rnn_hidden_size, bidirectional=False, batch_first=True, padding_idx=0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            embedding_size (int): The size of the character embeddings\n",
    "            num_embeddings (int): The number of characters to embed\n",
    "            num_classes (int): The size of the prediction vector \n",
    "                Note: For binary classification, this should be 1\n",
    "            bidirectional (bool): Informs whether bidrectional RNN is used\n",
    "            rnn_hidden_size (int): The size of the RNN's hidden state\n",
    "            batch_first (bool): Informs whether the input tensors will \n",
    "                have batch or the sequence on the 0th dimension\n",
    "            padding_idx (int): The index for the tensor padding; \n",
    "                see torch.nn.Embedding\n",
    "        \"\"\"\n",
    "        super(NewsClassifier, self).__init__()\n",
    "\n",
    "        if bidirectional == False:\n",
    "             self.num_directions = 1\n",
    "        else:\n",
    "             self.num_directions = 2\n",
    "        \n",
    "        self.emb = nn.Embedding(num_embeddings=num_embeddings,    # E.g., (80, 100)\n",
    "                                embedding_dim=embedding_size,\n",
    "                                padding_idx=padding_idx)          # mask_index (padding index) is 0\n",
    "\n",
    "        #self.rnn = nn.RNN(input_size=embedding_size,              # E.g., 100\n",
    "        #self.rnn = nn.GRU(input_size=embedding_size,\n",
    "        self.rnn = nn.LSTM(input_size=embedding_size,\n",
    "                             hidden_size=rnn_hidden_size,         # E.g., 64\n",
    "                             batch_first=batch_first, \n",
    "                             num_layers = 1,\n",
    "                             dropout = 0.0, \n",
    "                             bidirectional=bidirectional)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=rnn_hidden_size*self.num_directions,  # 64*1 for unidirectinal; 64*2 for bidirectional\n",
    "                         out_features=rnn_hidden_size*self.num_directions)\n",
    "        self.fc2 = nn.Linear(in_features=rnn_hidden_size*self.num_directions,\n",
    "                          out_features=1)                            # 1 output for binary classification\n",
    "        # for batch norm & dropout\n",
    "        self.bn1 = nn.BatchNorm1d(rnn_hidden_size*self.num_directions) \n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "\n",
    "    def forward(self, x_in, x_lengths=None, apply_softmax=False):\n",
    "        \"\"\"The forward pass of the classifier\n",
    "        \n",
    "        Args:\n",
    "            x_in (torch.Tensor): an input data tensor. \n",
    "                x_in.shape should be (batch, input_dim, i.e. seq_size)\n",
    "            x_lengths (torch.Tensor): the lengths of each sequence in the batch.\n",
    "                They are used to find the final vector of each sequence: (batch,)\n",
    "            apply_softmax (bool): a flag for the softmax activation\n",
    "                should be false if used with the Cross Entropy losses\n",
    "        Returns:\n",
    "            the resulting tensor. tensor.shape should be (batch, 1) for binary classification\n",
    "        \"\"\"\n",
    "        x_embedded = self.emb(x_in)      # (batch, seq_size)->(batch, seq_size, feat_size) ; E.g., (64,19)->(64,19,100)\n",
    "        \n",
    "        y_out, _ = self.rnn(x_embedded)  # (batch, seq_size, feat_size) -> (batch, seq_size, hidden_size*num_directions)\n",
    "                                         # (64,19,100) -> (64,19,64*num_directions)\n",
    "      \n",
    "        if x_lengths is not None:        # (batch, ) ; e.g., (64,) ; e.g., [9, 6, 11, 9, 7, ...., 12]\n",
    "            #y_out = column_gather(y_out, x_lengths)  # y_out gets the last hidden vector of each input: (batch, hidden_size*num_directions)\n",
    "                                                     # (64, 64*num_direction)\n",
    "                                                     # but, the last hidden vector of last character, not including padding\n",
    "                                                     # e.g., get the last hidden vetor from y_out[batch_no, 9] instead of y_out[batch_no, 18].\n",
    "\n",
    "            # uncomment code below for task 2, and comment out the line above.\n",
    "            # y_out gets the max or mean hidden vector of each input\n",
    "            y_out = column_summation(y_out, x_lengths, mode=\"mean\") \n",
    "        else:\n",
    "            y_out = y_out[:, -1, :]      # y_out gets the last hidden vector of each input: (batch, hidden_size*num_directions)\n",
    "                                         # (64, 64*num_direction)\n",
    "            \n",
    "        # with batch norm and dropout\n",
    "        # F.dropout(y_out, 0.2, training=self.training) can also be used as an alternative to self.dropout(y_out) \n",
    "        y_out = F.relu(self.bn1(self.fc1(self.dropout(y_out))))  # y_out: (64, 64*num_direction)\n",
    "\n",
    "        \n",
    "        # with dropout\n",
    "        y_out = self.fc2(self.dropout(y_out))   # y_out: (batch, 1) for binary classification\n",
    "\n",
    "        if apply_softmax:\n",
    "            y_out = torch.sigmoid(y_out)  # Use sigmoid for binary classification instead of softmax\n",
    "\n",
    "        return y_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc7e031",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed_everywhere(seed, cuda):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if cuda:\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def handle_dirs(dirpath):\n",
    "    if not os.path.exists(dirpath):\n",
    "        os.makedirs(dirpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997a9d50",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac262ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA: False\n"
     ]
    }
   ],
   "source": [
    "args = Namespace(\n",
    "    # Data and path information\n",
    "    output_news_csv='Data/preprocessed_news.csv',\n",
    "    model_state_file=\"model.pth\",\n",
    "    save_dir=\"model_storage/ch6/news_classification\",\n",
    "    # Model hyper parameter\n",
    "    char_embedding_size=100,\n",
    "    rnn_hidden_size=64,\n",
    "    bidirectional=False,\n",
    "    # Training hyper parameter\n",
    "    num_epochs=10,  # Reduced from 100 to 10 for testing\n",
    "    learning_rate=1e-3,\n",
    "    batch_size=32,  # Reduced from 64 to 32 to save memory\n",
    "    seed=1337,\n",
    "    early_stopping_criteria=5,\n",
    "    # Runtime hyper parameter\n",
    "    cuda=True,\n",
    "    catch_keyboard_interrupt=True,\n",
    "    expand_filepaths_to_save_dir=True,\n",
    ")\n",
    "\n",
    "# Check CUDA\n",
    "if not torch.cuda.is_available():\n",
    "    args.cuda = False\n",
    "\n",
    "args.device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
    "    \n",
    "print(\"Using CUDA: {}\".format(args.cuda))\n",
    "\n",
    "\n",
    "if args.expand_filepaths_to_save_dir:\n",
    "    args.model_state_file = os.path.join(args.save_dir, args.model_state_file)\n",
    "    \n",
    "# Set seed for reproducibility\n",
    "set_seed_everywhere(args.seed, args.cuda)\n",
    "\n",
    "# handle dirs\n",
    "handle_dirs(args.save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661c3cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset and vectorizer with limited sequence length\n",
    "dataset = NewsDataset.load_dataset_and_make_vectorizer(args.output_news_csv, max_seq_length=5000)\n",
    "\n",
    "vectorizer = dataset.get_vectorizer()\n",
    "\n",
    "classifier = NewsClassifier(embedding_size=args.char_embedding_size, \n",
    "                               num_embeddings=len(vectorizer.news_vocab),\n",
    "                               num_classes=1,  # Binary classification\n",
    "                               rnn_hidden_size=args.rnn_hidden_size,\n",
    "                               padding_idx=vectorizer.news_vocab.mask_index,\n",
    "                               bidirectional=args.bidirectional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdcfa0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing data loading...\n",
      "Original text length: 1500 words\n",
      "Vectorized length: 1503\n",
      "Vector shape: (5000,)\n",
      "Max sequence length: 5000\n",
      "Batch shape: torch.Size([2, 5000])\n",
      "Target shape: torch.Size([2])\n",
      "Length shape: torch.Size([2])\n",
      "Data loading test passed!\n"
     ]
    }
   ],
   "source": [
    "# Test data loading to ensure everything works\n",
    "print(\"Testing data loading...\")\n",
    "dataset.set_split('train')\n",
    "\n",
    "# Test vectorization with a long text\n",
    "test_text = \"This is a very long text that should be truncated properly when we vectorize it. \" * 100\n",
    "print(f\"Original text length: {len(test_text.split())} words\")\n",
    "\n",
    "vectorized, length = dataset._vectorizer.vectorize(test_text, dataset._max_seq_length)\n",
    "print(f\"Vectorized length: {length}\")\n",
    "print(f\"Vector shape: {vectorized.shape}\")\n",
    "print(f\"Max sequence length: {dataset._max_seq_length}\")\n",
    "\n",
    "# Test batch loading\n",
    "test_batch = next(iter(generate_batches(dataset, batch_size=2, device=args.device)))\n",
    "print(f\"Batch shape: {test_batch['x_data'].shape}\")\n",
    "print(f\"Target shape: {test_batch['y_target'].shape}\")\n",
    "print(f\"Length shape: {test_batch['x_length'].shape}\")\n",
    "print(\"Data loading test passed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5960a23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset._max_seq_length # max sequence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a807c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<MASK>': 0,\n",
       " '<UNK>': 1,\n",
       " '<BEGIN>': 2,\n",
       " '<END>': 3,\n",
       " 'jake': 4,\n",
       " 'tapper': 5,\n",
       " 'burns': 6,\n",
       " 'trump': 7,\n",
       " 'with': 8,\n",
       " 'bill': 9,\n",
       " 'maher': 10,\n",
       " 'he': 11,\n",
       " 'is': 12,\n",
       " 'empirically': 13,\n",
       " 'indecent': 14,\n",
       " 'video': 15,\n",
       " 'a': 16,\n",
       " 'lot': 17,\n",
       " 'about': 18,\n",
       " 'america': 19,\n",
       " 'has': 20,\n",
       " 'changed': 21,\n",
       " 'since': 22,\n",
       " 'the': 23,\n",
       " 'rise': 24,\n",
       " 'of': 25,\n",
       " 'donald': 26,\n",
       " 'people': 27,\n",
       " 'thought': 28,\n",
       " 'that': 29,\n",
       " 'his': 30,\n",
       " 'coarse': 31,\n",
       " 'language': 32,\n",
       " 'clear': 33,\n",
       " 'racism': 34,\n",
       " 'and': 35,\n",
       " 'misogyny': 36,\n",
       " 'just': 37,\n",
       " 'generally': 38,\n",
       " 'appalling': 39,\n",
       " 'behavior': 40,\n",
       " 'would': 41,\n",
       " 'render': 42,\n",
       " 'him': 43,\n",
       " 'unacceptable': 44,\n",
       " 'to': 45,\n",
       " 'american': 46,\n",
       " 'public': 47,\n",
       " 'yet': 48,\n",
       " 'here': 49,\n",
       " 'we': 50,\n",
       " 'are': 51,\n",
       " 'president': 52,\n",
       " 'young': 53,\n",
       " 'administration': 54,\n",
       " 'fundamentally': 55,\n",
       " 'how': 56,\n",
       " 'world': 57,\n",
       " 'views': 58,\n",
       " 'its': 59,\n",
       " 'citizens': 60,\n",
       " 'government': 61,\n",
       " 'one': 62,\n",
       " 'thing': 63,\n",
       " 'hasn': 64,\n",
       " 't': 65,\n",
       " 'though': 66,\n",
       " 'way': 67,\n",
       " 'some': 68,\n",
       " 'strident': 69,\n",
       " 'brave': 70,\n",
       " 'media': 71,\n",
       " 'personalities': 72,\n",
       " 'continue': 73,\n",
       " 'speak': 74,\n",
       " 'truth': 75,\n",
       " 'power': 76,\n",
       " 'insist': 77,\n",
       " 'on': 78,\n",
       " 'making': 79,\n",
       " 'sure': 80,\n",
       " 's': 81,\n",
       " 'disgusting': 82,\n",
       " 'ways': 83,\n",
       " 'incompetence': 84,\n",
       " 'lies': 85,\n",
       " 'don': 86,\n",
       " 'change': 87,\n",
       " 'who': 88,\n",
       " 'as': 89,\n",
       " 'perhaps': 90,\n",
       " 'breakout': 91,\n",
       " 'star': 92,\n",
       " 'in': 93,\n",
       " 'regard': 94,\n",
       " 'cnn': 95,\n",
       " 'hosts': 96,\n",
       " 'lead': 97,\n",
       " 'during': 98,\n",
       " 'week': 99,\n",
       " 'state': 100,\n",
       " 'union': 101,\n",
       " 'sunday': 102,\n",
       " 'mornings': 103,\n",
       " 'friday': 104,\n",
       " 'night': 105,\n",
       " 'fiery': 106,\n",
       " 'host': 107,\n",
       " 'stopped': 108,\n",
       " 'by': 109,\n",
       " 'hbo': 110,\n",
       " 'real': 111,\n",
       " 'time': 112,\n",
       " 'have': 113,\n",
       " 'chat': 114,\n",
       " 'course': 115,\n",
       " 'had': 116,\n",
       " 'ask': 117,\n",
       " 'changes': 118,\n",
       " 'make': 119,\n",
       " 'now': 120,\n",
       " 'there': 121,\n",
       " 'biggest': 122,\n",
       " 'liar': 123,\n",
       " 'earth': 124,\n",
       " 'occupying': 125,\n",
       " 'oval': 126,\n",
       " 'office': 127,\n",
       " 'responded': 128,\n",
       " 'you': 129,\n",
       " 've': 130,\n",
       " 'been': 131,\n",
       " 'covering': 132,\n",
       " 'politicians': 133,\n",
       " 'for': 134,\n",
       " 'long': 135,\n",
       " 'lie': 136,\n",
       " 'it': 137,\n",
       " 'wasn': 138,\n",
       " 'invented': 139,\n",
       " 'jan': 140,\n",
       " '20': 141,\n",
       " 'i': 142,\n",
       " 'never': 143,\n",
       " 'seen': 144,\n",
       " 'this': 145,\n",
       " 'level': 146,\n",
       " 'falsehood': 147,\n",
       " 'quantitatively': 148,\n",
       " 'went': 149,\n",
       " 'distinguish': 150,\n",
       " 'between': 151,\n",
       " 'what': 152,\n",
       " 'happens': 153,\n",
       " 'say': 154,\n",
       " 'falsehoods': 155,\n",
       " 'happened': 156,\n",
       " 'obama': 157,\n",
       " 'such': 158,\n",
       " 'if': 159,\n",
       " 'like': 160,\n",
       " 'your': 161,\n",
       " 'doctor': 162,\n",
       " 'can': 163,\n",
       " 'keep': 164,\n",
       " 'says': 165,\n",
       " 'coming': 166,\n",
       " 'out': 167,\n",
       " 'white': 168,\n",
       " 'house': 169,\n",
       " 'conspiracy': 170,\n",
       " 'theories': 171,\n",
       " 'based': 172,\n",
       " 'nothing': 173,\n",
       " 'members': 174,\n",
       " 'own': 175,\n",
       " 'party': 176,\n",
       " 'distancing': 177,\n",
       " 'themselves': 178,\n",
       " 'from': 179,\n",
       " 'then': 180,\n",
       " 'conversation': 181,\n",
       " 'turns': 182,\n",
       " 'vulgarity': 183,\n",
       " 'other': 184,\n",
       " 'fundamental': 185,\n",
       " 'affronts': 186,\n",
       " 'basic': 187,\n",
       " 'human': 188,\n",
       " 'decency': 189,\n",
       " 'discourse': 190,\n",
       " 'behaved': 191,\n",
       " 'campaign': 192,\n",
       " 'trail': 193,\n",
       " 'continues': 194,\n",
       " 'behave': 195,\n",
       " 'matter': 196,\n",
       " 'no': 197,\n",
       " 'bias': 198,\n",
       " 'when': 199,\n",
       " 'comes': 200,\n",
       " 'facts': 201,\n",
       " 'fun': 202,\n",
       " 'disabled': 203,\n",
       " 'my': 204,\n",
       " 'children': 205,\n",
       " 'know': 206,\n",
       " 'better': 207,\n",
       " 'than': 208,\n",
       " 'two': 209,\n",
       " 'reference': 210,\n",
       " 'all': 211,\n",
       " 'which': 212,\n",
       " 'most': 213,\n",
       " 'things': 214,\n",
       " 'so': 215,\n",
       " 'awful': 216,\n",
       " 'learn': 217,\n",
       " 'not': 218,\n",
       " 'do': 219,\n",
       " 'grade': 220,\n",
       " 'school': 221,\n",
       " 'always': 222,\n",
       " 'think': 223,\n",
       " 'book': 224,\n",
       " 'everything': 225,\n",
       " 'needed': 226,\n",
       " 'learned': 227,\n",
       " 'kindergarten': 228,\n",
       " 'violates': 229,\n",
       " 'every': 230,\n",
       " 'rule': 231,\n",
       " 'accuse': 232,\n",
       " 'they': 233,\n",
       " 're': 234,\n",
       " 'guilty': 235,\n",
       " 'boast': 236,\n",
       " 'pay': 237,\n",
       " 'taxes': 238,\n",
       " 'serve': 239,\n",
       " 'country': 240,\n",
       " 'be': 241,\n",
       " 'racist': 242,\n",
       " 'insult': 243,\n",
       " 'handicapped': 244,\n",
       " 'or': 245,\n",
       " 'lucky': 246,\n",
       " 'great': 247,\n",
       " 'looking': 248,\n",
       " 'spite': 249,\n",
       " 'these': 250,\n",
       " 'still': 251,\n",
       " 'voted': 252,\n",
       " 'sorry': 253,\n",
       " 'excuse': 254,\n",
       " 'being': 255,\n",
       " 'nation': 256,\n",
       " 'really': 257,\n",
       " 'need': 258,\n",
       " 'examine': 259,\n",
       " 'should': 260,\n",
       " 'survive': 261,\n",
       " 'nightmare': 262,\n",
       " 'presidency': 263,\n",
       " 'watch': 264,\n",
       " 'below': 265,\n",
       " 'featured': 266,\n",
       " 'image': 267,\n",
       " 'via': 268,\n",
       " 'scott': 269,\n",
       " 'eisen': 270,\n",
       " 'getty': 271,\n",
       " 'images': 272,\n",
       " 'news': 273,\n",
       " 'buried': 274,\n",
       " 'aide': 275,\n",
       " 'leftist': 276,\n",
       " 'us': 277,\n",
       " 'congressman': 278,\n",
       " 'sander': 279,\n",
       " 'levin': 280,\n",
       " 'd': 281,\n",
       " 'mi': 282,\n",
       " 'arrested': 283,\n",
       " 'brutally': 284,\n",
       " 'beating': 285,\n",
       " 'male': 286,\n",
       " 'lover': 287,\n",
       " 'shovel': 288,\n",
       " 'want': 289,\n",
       " 'kill': 290,\n",
       " 'die': 291,\n",
       " 'dirty': 292,\n",
       " 'faggy': 293,\n",
       " 'muslims': 294,\n",
       " 'cornered': 295,\n",
       " 'market': 296,\n",
       " 'abusing': 297,\n",
       " 'gays': 298,\n",
       " 'won': 299,\n",
       " 'see': 300,\n",
       " 'story': 301,\n",
       " 'mainstream': 302,\n",
       " 'please': 303,\n",
       " 'feel': 304,\n",
       " 'free': 305,\n",
       " 'share': 306,\n",
       " 'baltimore': 307,\n",
       " 'city': 308,\n",
       " 'police': 309,\n",
       " 'an': 310,\n",
       " 'rep': 311,\n",
       " 'm': 312,\n",
       " 'mich': 313,\n",
       " 'at': 314,\n",
       " 'around': 315,\n",
       " '2': 316,\n",
       " '30': 317,\n",
       " 'oct': 318,\n",
       " '8': 319,\n",
       " 'criminal': 320,\n",
       " 'domestic': 321,\n",
       " 'violence': 322,\n",
       " 'charges': 323,\n",
       " 'tim': 324,\n",
       " 'foster': 325,\n",
       " 'native': 326,\n",
       " 'henderson': 327,\n",
       " 'ky': 328,\n",
       " 'beat': 329,\n",
       " 'small': 330,\n",
       " 'black': 331,\n",
       " 'red': 332,\n",
       " 'according': 333,\n",
       " 'report': 334,\n",
       " 'obtained': 335,\n",
       " 'cq': 336,\n",
       " 'roll': 337,\n",
       " 'call': 338,\n",
       " 'leaving': 339,\n",
       " 'victim': 340,\n",
       " 'hospitalized': 341,\n",
       " 'abrasions': 342,\n",
       " 'bruises': 343,\n",
       " 'upper': 344,\n",
       " 'back': 345,\n",
       " 'neck': 346,\n",
       " 'torso': 347,\n",
       " 'dispute': 348,\n",
       " 'started': 349,\n",
       " '12': 350,\n",
       " 'inside': 351,\n",
       " 'northwest': 352,\n",
       " 'home': 353,\n",
       " '32': 354,\n",
       " 'got': 355,\n",
       " 'into': 356,\n",
       " 'verbal': 357,\n",
       " 'argument': 358,\n",
       " '39': 359,\n",
       " 'year': 360,\n",
       " 'old': 361,\n",
       " 'identified': 362,\n",
       " 'boyfriend': 363,\n",
       " 'put': 364,\n",
       " 'choke': 365,\n",
       " 'hold': 366,\n",
       " 'stated': 367,\n",
       " 'man': 368,\n",
       " 'later': 369,\n",
       " 'told': 370,\n",
       " 'released': 371,\n",
       " 'allegedly': 372,\n",
       " 'grabbed': 373,\n",
       " 'stainless': 374,\n",
       " 'kitchen': 375,\n",
       " 'knife': 376,\n",
       " 'fled': 377,\n",
       " 'toward': 378,\n",
       " 'stairs': 379,\n",
       " 'chased': 380,\n",
       " 'warned': 381,\n",
       " 'reach': 382,\n",
       " 'fifth': 383,\n",
       " 'step': 384,\n",
       " 'am': 385,\n",
       " 'going': 386,\n",
       " 'stab': 387,\n",
       " 'lunged': 388,\n",
       " 'but': 389,\n",
       " 'wife': 390,\n",
       " 'fell': 391,\n",
       " 'floor': 392,\n",
       " 'states': 393,\n",
       " 'attempted': 394,\n",
       " 'escape': 395,\n",
       " 'property': 396,\n",
       " 'was': 397,\n",
       " 'again': 398,\n",
       " 'assaulted': 399,\n",
       " 'struck': 400,\n",
       " 'continued': 401,\n",
       " 'assault': 402,\n",
       " 'until': 403,\n",
       " 'vehicle': 404,\n",
       " 'memorial': 405,\n",
       " 'hospital': 406,\n",
       " 'where': 407,\n",
       " 'spoke': 408,\n",
       " 'placed': 409,\n",
       " 'under': 410,\n",
       " 'arrest': 411,\n",
       " 'early': 412,\n",
       " 'thursday': 413,\n",
       " 'morning': 414,\n",
       " 'locked': 415,\n",
       " 'up': 416,\n",
       " 'county': 417,\n",
       " 'detention': 418,\n",
       " 'center': 419,\n",
       " 'submitted': 420,\n",
       " 'evidence': 421,\n",
       " 'court': 422,\n",
       " 'records': 423,\n",
       " 'show': 424,\n",
       " 'committed': 425,\n",
       " 'overnight': 426,\n",
       " 'faces': 427,\n",
       " 'second': 428,\n",
       " 'degree': 429,\n",
       " 'dangerous': 430,\n",
       " 'weapons': 431,\n",
       " 'employed': 432,\n",
       " 'seven': 433,\n",
       " 'years': 434,\n",
       " 'current': 435,\n",
       " 'post': 436,\n",
       " 'online': 437,\n",
       " 'communication': 438,\n",
       " 'manager': 439,\n",
       " 'may': 440,\n",
       " '2013': 441,\n",
       " 'wake': 442,\n",
       " 'incident': 443,\n",
       " 'unpaid': 444,\n",
       " 'leave': 445,\n",
       " 'politics': 446,\n",
       " 'clown': 447,\n",
       " 'cries': 448,\n",
       " 'fake': 449,\n",
       " 'uses': 450,\n",
       " 'unverified': 451,\n",
       " 'push': 452,\n",
       " 'islamaphobia': 453,\n",
       " 'viewers': 454,\n",
       " 'youtube': 455,\n",
       " 'prankster': 456,\n",
       " 'named': 457,\n",
       " 'adam': 458,\n",
       " 'saleh': 459,\n",
       " 'claiming': 460,\n",
       " 'kicked': 461,\n",
       " 'off': 462,\n",
       " 'delta': 463,\n",
       " 'flight': 464,\n",
       " 'speaking': 465,\n",
       " 'arabic': 466,\n",
       " 'airline': 467,\n",
       " 'concluded': 468,\n",
       " 'investigation': 469,\n",
       " 'engaging': 470,\n",
       " 'provacative': 471,\n",
       " 'https': 472,\n",
       " 'www': 473,\n",
       " 'com': 474,\n",
       " 'v': 475,\n",
       " '5': 476,\n",
       " 's5gs0i4uw': 477,\n",
       " 'interview': 478,\n",
       " 'hill': 479,\n",
       " 'reporter': 480,\n",
       " 'former': 481,\n",
       " 'mediaite': 482,\n",
       " 'columnist': 483,\n",
       " 'joe': 484,\n",
       " 'concha': 485,\n",
       " 'carlson': 486,\n",
       " 'said': 487,\n",
       " 'stelter': 488,\n",
       " 'regularly': 489,\n",
       " 'urges': 490,\n",
       " 'organizations': 491,\n",
       " 'proceed': 492,\n",
       " 'caution': 493,\n",
       " 'cases': 494,\n",
       " 'failed': 495,\n",
       " 'practice': 496,\n",
       " 'preaches': 497,\n",
       " 'googling': 498,\n",
       " 'discover': 499,\n",
       " 'history': 500,\n",
       " 'posting': 501,\n",
       " 'similar': 502,\n",
       " 'videos': 503,\n",
       " 'mediaitein': 504,\n",
       " 'statement': 505,\n",
       " 'customers': 506,\n",
       " 'were': 507,\n",
       " 'removed': 508,\n",
       " 'rebooked': 509,\n",
       " 'after': 510,\n",
       " 'disturbance': 511,\n",
       " 'cabin': 512,\n",
       " 'resulted': 513,\n",
       " 'more': 514,\n",
       " 'expressing': 515,\n",
       " 'their': 516,\n",
       " 'discomfort': 517,\n",
       " 'conducting': 518,\n",
       " 'full': 519,\n",
       " 'review': 520,\n",
       " 'understand': 521,\n",
       " 'transpired': 522,\n",
       " 'taking': 523,\n",
       " 'allegations': 524,\n",
       " 'discrimination': 525,\n",
       " 'very': 526,\n",
       " 'seriously': 527,\n",
       " 'our': 528,\n",
       " 'culture': 529,\n",
       " 'requires': 530,\n",
       " 'treating': 531,\n",
       " 'others': 532,\n",
       " 'respect': 533,\n",
       " '1': 534,\n",
       " '6': 535,\n",
       " 'million': 536,\n",
       " 'subscribers': 537,\n",
       " 'truestoryasa': 538,\n",
       " 'channel': 539,\n",
       " 'vlogs': 540,\n",
       " 'channels': 541,\n",
       " 'prank': 542,\n",
       " 'well': 543,\n",
       " 'muslim': 544,\n",
       " 'life': 545,\n",
       " 'self': 546,\n",
       " 'described': 547,\n",
       " 'professional': 548,\n",
       " 'idiot': 549,\n",
       " 'twitter': 550,\n",
       " 'deltaclick': 551,\n",
       " 'facebookcall': 552,\n",
       " '800': 553,\n",
       " '221': 554,\n",
       " '1212': 555,\n",
       " 'customer': 556,\n",
       " 'servicelet': 557,\n",
       " 'airlines': 558,\n",
       " 'stand': 559,\n",
       " 'decision': 560,\n",
       " 'pranksters': 561,\n",
       " 'because': 562,\n",
       " 'terrorism': 563,\n",
       " 'islamic': 564,\n",
       " 'radicals': 565,\n",
       " 'against': 566,\n",
       " 'innocent': 567,\n",
       " 'laughing': 568,\n",
       " 'delusional': 569,\n",
       " 'divided': 570,\n",
       " 'become': 571,\n",
       " 'least': 572,\n",
       " 'civil': 573,\n",
       " 'war': 574,\n",
       " 'veterans': 575,\n",
       " 'cozy': 576,\n",
       " 'relationship': 577,\n",
       " 'russian': 578,\n",
       " 'hackers': 579,\n",
       " 'cause': 580,\n",
       " 'alarm': 581,\n",
       " 'military': 582,\n",
       " 'extreme': 583,\n",
       " 'concerns': 584,\n",
       " 'reaction': 585,\n",
       " 'revelation': 586,\n",
       " 'employ': 587,\n",
       " 'russia': 588,\n",
       " 'stole': 589,\n",
       " 'information': 590,\n",
       " 'democrats': 591,\n",
       " 'passed': 592,\n",
       " 'wikileaks': 593,\n",
       " 'attempt': 594,\n",
       " 'influence': 595,\n",
       " 'result': 596,\n",
       " 'election': 597,\n",
       " 'while': 598,\n",
       " 'congressional': 599,\n",
       " 'republicans': 600,\n",
       " 'down': 601,\n",
       " 'played': 602,\n",
       " 'pushing': 603,\n",
       " 'retired': 604,\n",
       " 'major': 605,\n",
       " 'general': 606,\n",
       " 'paul': 607,\n",
       " 'eaton': 608,\n",
       " 'senior': 609,\n",
       " 'adviser': 610,\n",
       " 'votevets': 611,\n",
       " 'org': 612,\n",
       " 'blasting': 613,\n",
       " 'republican': 614,\n",
       " 'moment': 615,\n",
       " 'elect': 616,\n",
       " 'united': 617,\n",
       " 'enamored': 618,\n",
       " 'regime': 619,\n",
       " 'national': 620,\n",
       " 'security': 621,\n",
       " 'potential': 622,\n",
       " 'secretary': 623,\n",
       " 'find': 624,\n",
       " 'interfered': 625,\n",
       " 'help': 626,\n",
       " 'side': 627,\n",
       " 'join': 628,\n",
       " 'senator': 629,\n",
       " 'wyden': 630,\n",
       " 'intelligence': 631,\n",
       " 'committee': 632,\n",
       " 'calling': 633,\n",
       " 'materials': 634,\n",
       " 'hacking': 635,\n",
       " 'declassified': 636,\n",
       " 'immediately': 637,\n",
       " 'also': 638,\n",
       " 'group': 639,\n",
       " '10': 640,\n",
       " 'electoral': 641,\n",
       " 'college': 642,\n",
       " 'recently': 643,\n",
       " 'asked': 644,\n",
       " 'turned': 645,\n",
       " 'over': 646,\n",
       " 'them': 647,\n",
       " 'tell': 648,\n",
       " 'cia': 649,\n",
       " 'found': 650,\n",
       " 'deserve': 651,\n",
       " 'those': 652,\n",
       " 'right': 653,\n",
       " 'asks': 654,\n",
       " 'did': 655,\n",
       " 'anyone': 656,\n",
       " 'connected': 657,\n",
       " 'plot': 658,\n",
       " 'manipulate': 659,\n",
       " 'outcome': 660,\n",
       " '2016': 661,\n",
       " 'induce': 662,\n",
       " 'fear': 663,\n",
       " 'millions': 664,\n",
       " 'americans': 665,\n",
       " 'telling': 666,\n",
       " 'among': 667,\n",
       " 'concern': 668,\n",
       " 'actions': 669,\n",
       " 'putin': 670,\n",
       " 'dire': 671,\n",
       " 'terms': 672,\n",
       " 'fresh': 673,\n",
       " 'partisan': 674,\n",
       " 'benghazi': 675,\n",
       " 'largely': 676,\n",
       " 'whipped': 677,\n",
       " 'attack': 678,\n",
       " 'hillary': 679,\n",
       " 'clinton': 680,\n",
       " 'slow': 681,\n",
       " 'walked': 682,\n",
       " 'responses': 683,\n",
       " 'actively': 684,\n",
       " 'opposing': 685,\n",
       " 'any': 686,\n",
       " 'sort': 687,\n",
       " 'could': 688,\n",
       " 'harm': 689,\n",
       " 'nyc': 690,\n",
       " 'parks': 691,\n",
       " 'rec': 692,\n",
       " 'mocks': 693,\n",
       " 'remove': 694,\n",
       " 'naked': 695,\n",
       " 'statue': 696,\n",
       " 'reported': 697,\n",
       " 'earlier': 698,\n",
       " 'statues': 699,\n",
       " 'appearing': 700,\n",
       " 'artists': 701,\n",
       " 'installations': 702,\n",
       " 'through': 703,\n",
       " 'sculptures': 704,\n",
       " 'behind': 705,\n",
       " 'physical': 706,\n",
       " 'metaphorical': 707,\n",
       " 'embodiment': 708,\n",
       " 'ghastly': 709,\n",
       " 'soul': 710,\n",
       " 'infamous': 711,\n",
       " 'reviled': 712,\n",
       " 'ain': 713,\n",
       " 'interestingly': 714,\n",
       " 'enough': 715,\n",
       " 'depiction': 716,\n",
       " 'estate': 717,\n",
       " 'mogul': 718,\n",
       " 'reality': 719,\n",
       " 'television': 720,\n",
       " 'egomaniac': 721,\n",
       " 'likely': 722,\n",
       " 'remarkably': 723,\n",
       " 'lifelike': 724,\n",
       " 'take': 725,\n",
       " 'look': 726,\n",
       " 'sculpture': 727,\n",
       " 'new': 728,\n",
       " 'york': 729,\n",
       " 'square': 730,\n",
       " 'o': 731,\n",
       " 'whoever': 732,\n",
       " 'installed': 733,\n",
       " 'last': 734,\n",
       " 'pic': 735,\n",
       " 'cldd4qkgyi': 736,\n",
       " 'jamesmichael': 737,\n",
       " 'nichols': 738,\n",
       " 'august': 739,\n",
       " '18': 740,\n",
       " '2016clearly': 741,\n",
       " 'kinda': 742,\n",
       " 'sorta': 743,\n",
       " 'inappropriate': 744,\n",
       " 'entertaining': 745,\n",
       " 'hilarious': 746,\n",
       " 'however': 747,\n",
       " 'knowing': 748,\n",
       " 'couldn': 749,\n",
       " 'stay': 750,\n",
       " 'recreation': 751,\n",
       " 'department': 752,\n",
       " 'issued': 753,\n",
       " 'stands': 754,\n",
       " 'firmly': 755,\n",
       " 'unpermitted': 756,\n",
       " 'erection': 757,\n",
       " 'nude': 758,\n",
       " 'co': 759,\n",
       " 'hrb03msy0g': 760,\n",
       " 'ucyzaxztm7': 761,\n",
       " 'associated': 762,\n",
       " 'press': 763,\n",
       " 'ap': 764,\n",
       " '2016boom': 765,\n",
       " 'ha': 766,\n",
       " 'remark': 767,\n",
       " 'especially': 768,\n",
       " 'kind': 769,\n",
       " 'slap': 770,\n",
       " 'face': 771,\n",
       " 'narcissism': 772,\n",
       " 'constant': 773,\n",
       " 'attention': 774,\n",
       " 'talking': 775,\n",
       " 'plans': 776,\n",
       " 'best': 777,\n",
       " 'pretty': 778,\n",
       " 'obvious': 779,\n",
       " 'overcompensating': 780,\n",
       " 'something': 781,\n",
       " 'installation': 782,\n",
       " 'seem': 783,\n",
       " 'good': 784,\n",
       " 'idea': 785,\n",
       " 'photo': 786,\n",
       " 'spencer': 787,\n",
       " 'platt': 788,\n",
       " 'wow': 789,\n",
       " 'political': 790,\n",
       " 'organization': 791,\n",
       " 'takes': 792,\n",
       " 'credit': 793,\n",
       " 'dallas': 794,\n",
       " 'cop': 795,\n",
       " 'slayings': 796,\n",
       " 'facebook': 797,\n",
       " 'page': 798,\n",
       " 'shows': 799,\n",
       " 'snipers': 800,\n",
       " 'killed': 801,\n",
       " 'law': 802,\n",
       " 'enforcement': 803,\n",
       " 'officers': 804,\n",
       " 'yesterday': 805,\n",
       " 'shut': 806,\n",
       " 'managed': 807,\n",
       " 'capture': 808,\n",
       " 'screen': 809,\n",
       " 'shot': 810,\n",
       " 'comments': 811,\n",
       " 'few': 812,\n",
       " 'posts': 813,\n",
       " 'chance': 814,\n",
       " 'shuts': 815,\n",
       " 'bppo': 816,\n",
       " 'blackpower': 817,\n",
       " 'blackknights': 818,\n",
       " 'mission': 819,\n",
       " 'africa': 820,\n",
       " 'countries': 821,\n",
       " 'non': 822,\n",
       " 'control': 823,\n",
       " 'give': 824,\n",
       " 'opportunity': 825,\n",
       " 'develop': 826,\n",
       " 'powerful': 827,\n",
       " 'patriotic': 828,\n",
       " 'pro': 829,\n",
       " 'pan': 830,\n",
       " 'african': 831,\n",
       " 'leaders': 832,\n",
       " 'job': 833,\n",
       " 'avoid': 834,\n",
       " 'corruption': 835,\n",
       " 'bribery': 836,\n",
       " 'exploitation': 837,\n",
       " 'form': 838,\n",
       " 'ailments': 839,\n",
       " 'preventing': 840,\n",
       " 'reaching': 841,\n",
       " 'accomplish': 842,\n",
       " 'goal': 843,\n",
       " 'will': 844,\n",
       " 'working': 845,\n",
       " 'protection': 846,\n",
       " 'agency': 847,\n",
       " 'aka': 848,\n",
       " 'knights': 849,\n",
       " 'trained': 850,\n",
       " 'sniper': 851,\n",
       " 'assassins': 852,\n",
       " 'tens': 853,\n",
       " 'thousands': 854,\n",
       " 'located': 855,\n",
       " 'responsible': 856,\n",
       " 'fail': 857,\n",
       " 'equal': 858,\n",
       " 'rights': 859,\n",
       " 'justice': 860,\n",
       " 'relentlessly': 861,\n",
       " 'target': 862,\n",
       " 'assassinate': 863,\n",
       " 'influential': 864,\n",
       " 'families': 865,\n",
       " 'refuse': 866,\n",
       " 'finance': 867,\n",
       " 'taxation': 868,\n",
       " 'means': 869,\n",
       " 'yourself': 870,\n",
       " 'use': 871,\n",
       " 'economic': 872,\n",
       " 'sanctions': 873,\n",
       " 'exploit': 874,\n",
       " 'destroy': 875,\n",
       " 'economy': 876,\n",
       " 'terrorist': 877,\n",
       " 'only': 878,\n",
       " 'controlling': 879,\n",
       " 'methods': 880,\n",
       " 'western': 881,\n",
       " 'governments': 882,\n",
       " 'stop': 883,\n",
       " 'oppress': 884,\n",
       " 'example': 885,\n",
       " 'independent': 886,\n",
       " 'assassin': 887,\n",
       " 'dying': 888,\n",
       " 'losing': 889,\n",
       " 'love': 890,\n",
       " 'ones': 891,\n",
       " 'force': 892,\n",
       " 'someone': 893,\n",
       " 'close': 894,\n",
       " 'eg': 895,\n",
       " 'friends': 896,\n",
       " 'workers': 897,\n",
       " 'family': 898,\n",
       " 'etc': 899,\n",
       " 'poisoning': 900,\n",
       " 'playing': 901,\n",
       " 'choice': 902,\n",
       " 'play': 903,\n",
       " 'thank': 904,\n",
       " 'amazing': 905,\n",
       " 'nick': 906,\n",
       " 'short': 907,\n",
       " 'h': 908,\n",
       " 'left': 909,\n",
       " 'makes': 910,\n",
       " 'unprecedented': 911,\n",
       " 'move': 912,\n",
       " 'protect': 913,\n",
       " 'details': 914,\n",
       " 'barack': 915,\n",
       " 'knows': 916,\n",
       " 'doesn': 917,\n",
       " 'hell': 918,\n",
       " 'doing': 919,\n",
       " 'putting': 920,\n",
       " 'actually': 921,\n",
       " 'trying': 922,\n",
       " 'figure': 923,\n",
       " 'ropes': 924,\n",
       " 'agreed': 925,\n",
       " 'little': 926,\n",
       " 'orange': 927,\n",
       " 'hands': 928,\n",
       " 'remain': 929,\n",
       " 'guide': 930,\n",
       " 'transition': 931,\n",
       " 'period': 932,\n",
       " 'made': 933,\n",
       " 'save': 934,\n",
       " 'deadly': 935,\n",
       " 'monday': 936,\n",
       " 'beloved': 937,\n",
       " 'commander': 938,\n",
       " 'chief': 939,\n",
       " 'memo': 940,\n",
       " 'basically': 941,\n",
       " 'guidebook': 942,\n",
       " 'dummies': 943,\n",
       " 'document': 944,\n",
       " 'lays': 945,\n",
       " 'specific': 946,\n",
       " 'related': 947,\n",
       " 'topics': 948,\n",
       " 'first': 949,\n",
       " 'ever': 950,\n",
       " 'prevent': 951,\n",
       " 'completely': 952,\n",
       " 'unqualified': 953,\n",
       " 'person': 954,\n",
       " 'destroying': 955,\n",
       " 'washington': 956,\n",
       " 'eve': 957,\n",
       " 'promised': 958,\n",
       " 'aggressive': 959,\n",
       " 'counterterrorism': 960,\n",
       " 'operations': 961,\n",
       " 'lengthy': 962,\n",
       " 'compendium': 963,\n",
       " 'policies': 964,\n",
       " 'governing': 965,\n",
       " '61': 966,\n",
       " 'outlines': 967,\n",
       " 'eight': 968,\n",
       " 'legal': 969,\n",
       " 'opinions': 970,\n",
       " 'executive': 971,\n",
       " 'orders': 972,\n",
       " 'directives': 973,\n",
       " 'strong': 974,\n",
       " 'defense': 975,\n",
       " 'lists': 976,\n",
       " 'rules': 977,\n",
       " 'lethal': 978,\n",
       " 'drones': 979,\n",
       " 'describes': 980,\n",
       " 'international': 981,\n",
       " 'undergirds': 982,\n",
       " 'introduction': 983,\n",
       " 'created': 984,\n",
       " 'reduce': 985,\n",
       " 'risk': 986,\n",
       " 'ill': 987,\n",
       " 'considered': 988,\n",
       " 'observation': 989,\n",
       " 'lack': 990,\n",
       " 'emotional': 991,\n",
       " 'stability': 992,\n",
       " 'impulsive': 993,\n",
       " 'erratic': 994,\n",
       " 'wrote': 995,\n",
       " 'hate': 996,\n",
       " 'critical': 997,\n",
       " 'much': 998,\n",
       " 'possible': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.news_vocab._token_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee3bda5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{False: 0, True: 1}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.label_vocab._token_to_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751ae98d",
   "metadata": {},
   "source": [
    "## Training Routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc5e020",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_state(args):\n",
    "    return {'stop_early': False,\n",
    "            'early_stopping_step': 0,\n",
    "            'early_stopping_best_val': 1e8,\n",
    "            'learning_rate': args.learning_rate,\n",
    "            'epoch_index': 0,\n",
    "            'train_loss': [],\n",
    "            'train_acc': [],\n",
    "            'val_loss': [],\n",
    "            'val_acc': [],\n",
    "            'test_loss': -1,\n",
    "            'test_acc': -1,\n",
    "            'model_filename': args.model_state_file}\n",
    "\n",
    "\n",
    "def update_train_state(args, model, train_state):\n",
    "    \"\"\"Handle the training state updates.\n",
    "\n",
    "    Components:\n",
    "     - Early Stopping: Prevent overfitting.\n",
    "     - Model Checkpoint: Model is saved if the model is better\n",
    "    \n",
    "    :param args: main arguments\n",
    "    :param model: model to train\n",
    "    :param train_state: a dictionary representing the training state values\n",
    "    :returns:\n",
    "        a new train_state\n",
    "    \"\"\"\n",
    "\n",
    "    # Save one model at least\n",
    "    if train_state['epoch_index'] == 0:\n",
    "        torch.save(model.state_dict(), train_state['model_filename'])\n",
    "        train_state['stop_early'] = False\n",
    "\n",
    "    # Save model if performance improved\n",
    "    elif train_state['epoch_index'] >= 1:\n",
    "        loss_tm1, loss_t = train_state['val_loss'][-2:]\n",
    "         \n",
    "        # If loss worsened\n",
    "        #if loss_t >= loss_tm1: # if current loss becomes smaller than the previous loss, early_stopping_step is reset to 0.\n",
    "                                # this statement makes the model training time longer, compared to the statement below. \n",
    "        if loss_t >= train_state['early_stopping_best_val']:  # curent loss is compared with early_stopping_best_val loss value\n",
    "            # Update step\n",
    "            train_state['early_stopping_step'] += 1\n",
    "        # Loss decreased\n",
    "        else:\n",
    "            # Save the best model\n",
    "            if loss_t < train_state['early_stopping_best_val']:\n",
    "                torch.save(model.state_dict(), train_state['model_filename'])\n",
    "                train_state['early_stopping_best_val'] = loss_t\n",
    "\n",
    "            # Reset early stopping step\n",
    "            train_state['early_stopping_step'] = 0\n",
    "\n",
    "        # Stop early ?\n",
    "        train_state['stop_early'] = \\\n",
    "            train_state['early_stopping_step'] >= args.early_stopping_criteria\n",
    "\n",
    "    return train_state\n",
    "\n",
    "\n",
    "def compute_accuracy(y_pred, y_target, threshold=0.5):\n",
    "\n",
    "    \"\"\"Compute accuracy for binary classification\"\"\"\n",
    "\n",
    "    # Convert predictions to probabilities using sigmoid\n",
    "    y_prob = torch.sigmoid(y_pred)\n",
    "    # Convert probabilities to binary predictions\n",
    "    y_pred_class = (y_prob > threshold).float()\n",
    "    # Ensure targets are float for comparison\n",
    "    y_target_float = y_target.float()\n",
    "    # Calculate accuracy\n",
    "    correct = (y_pred_class == y_target_float).sum().item()\n",
    "    total = y_target_float.size(0)\n",
    "    return correct / total * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b5f774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset info:\n",
      "  Train size: 31427\n",
      "  Val size: 6734\n",
      "  Test size: 6737\n",
      "  Max sequence length: 5000\n",
      "  Batch size: 32\n",
      "  Train batches: 982\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3aedd05dfd44262b168038a88c53e8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training routine:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acd1a8094e4e405198acc8edfbfb957b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "split=train:   0%|          | 0/982 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57cd4db397a34cc38c66a1b0db326aef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "split=val:   0%|          | 0/210 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting loop\n"
     ]
    }
   ],
   "source": [
    "classifier = classifier.to(args.device)\n",
    "dataset.class_weights = dataset.class_weights.to(args.device)\n",
    "    \n",
    "loss_func = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=args.learning_rate)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, mode='min', factor=0.1, patience=10)\n",
    "\n",
    "train_state = make_train_state(args)\n",
    "\n",
    "# Print dataset info for debugging\n",
    "print(f\"Dataset info:\")\n",
    "print(f\"  Train size: {dataset.train_size}\")\n",
    "print(f\"  Val size: {dataset.validation_size}\")\n",
    "print(f\"  Test size: {dataset.test_size}\")\n",
    "print(f\"  Max sequence length: {dataset._max_seq_length}\")\n",
    "print(f\"  Batch size: {args.batch_size}\")\n",
    "print(f\"  Train batches: {dataset.get_num_batches(args.batch_size)}\")\n",
    "\n",
    "epoch_bar = tqdm(desc='training routine', total=args.num_epochs, position=0)\n",
    "\n",
    "dataset.set_split('train')\n",
    "train_bar = tqdm(desc='split=train', total=dataset.get_num_batches(args.batch_size), position=1, leave=True)\n",
    "\n",
    "dataset.set_split('val')\n",
    "val_bar = tqdm(desc='split=val', total=dataset.get_num_batches(args.batch_size), position=1, leave=True)\n",
    "\n",
    "try:\n",
    "\n",
    "    for epoch_index in range(args.num_epochs):\n",
    "        train_state['epoch_index'] = epoch_index\n",
    "\n",
    "        # Iterate over training dataset\n",
    "\n",
    "        # setup: batch generator, set loss and acc to 0, set train mode on\n",
    "        dataset.set_split('train')\n",
    "        batch_generator = generate_batches(dataset, \n",
    "                                           batch_size=args.batch_size, \n",
    "                                           device=args.device)\n",
    "        running_loss = 0.0\n",
    "        running_acc = 0.0\n",
    "        classifier.train()\n",
    "\n",
    "        for batch_index, batch_dict in enumerate(batch_generator):\n",
    "            # the training routine is these 5 steps:\n",
    "\n",
    "            # --------------------------------------    \n",
    "            # step 1. zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # step 2. compute the output\n",
    "            y_pred = classifier(x_in=batch_dict['x_data'], \n",
    "                        x_lengths=batch_dict['x_length'])\n",
    "\n",
    "            # 2. 修正 Target 形状并计算 Loss (使用前面建议的修正)\n",
    "            y_target = batch_dict['y_target'].float().unsqueeze(1) \n",
    "            loss = loss_func(y_pred, y_target) \n",
    "    \n",
    "            running_loss += (loss.item() - running_loss) / (batch_index + 1)\n",
    "\n",
    "            # step 4. use loss to produce gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # step 5. use optimizer to take gradient step\n",
    "            optimizer.step()\n",
    "            # -----------------------------------------\n",
    "            # compute the accuracy\n",
    "            acc_t = compute_accuracy(y_pred, y_target)\n",
    "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "\n",
    "            # update bar\n",
    "            train_bar.set_postfix(loss=running_loss, acc=running_acc, epoch=epoch_index)\n",
    "            train_bar.update()\n",
    "\n",
    "        train_state['train_loss'].append(running_loss)\n",
    "        train_state['train_acc'].append(running_acc)\n",
    "\n",
    "        # Iterate over val dataset\n",
    "\n",
    "        # setup: batch generator, set loss and acc to 0; set eval mode on\n",
    "\n",
    "        dataset.set_split('val')\n",
    "        batch_generator = generate_batches(dataset, \n",
    "                                           batch_size=args.batch_size, \n",
    "                                           device=args.device)\n",
    "        running_loss = 0.\n",
    "        running_acc = 0.\n",
    "        classifier.eval()\n",
    "\n",
    "        with torch.no_grad():  # Disable gradient computation\n",
    "          for batch_index, batch_dict in enumerate(batch_generator):\n",
    "            # compute the output\n",
    "            y_pred = classifier(x_in=batch_dict['x_data'], \n",
    "                        x_lengths=batch_dict['x_length'])\n",
    "\n",
    "            # 2. 修正 Target 形状并计算 Loss (使用前面建议的修正)\n",
    "            y_target = batch_dict['y_target'].float().unsqueeze(1) \n",
    "            loss = loss_func(y_pred, y_target) \n",
    "            running_loss += (loss.item() - running_loss) / (batch_index + 1)\n",
    "\n",
    "            # compute the accuracy\n",
    "            acc_t = compute_accuracy(y_pred, y_target)\n",
    "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "            val_bar.set_postfix(loss=running_loss, acc=running_acc, epoch=epoch_index)\n",
    "            val_bar.update()\n",
    "\n",
    "        train_state['val_loss'].append(running_loss)\n",
    "        train_state['val_acc'].append(running_acc)\n",
    "\n",
    "        train_state = update_train_state(args=args, model=classifier, \n",
    "                                         train_state=train_state)\n",
    "\n",
    "        scheduler.step(train_state['val_loss'][-1])\n",
    "\n",
    "        train_bar.reset()\n",
    "        val_bar.reset()\n",
    "        epoch_bar.update()\n",
    "\n",
    "        if train_state['stop_early']:\n",
    "            break\n",
    "            \n",
    "except KeyboardInterrupt:\n",
    "    print(\"Exiting loop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a00e5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "line": {
          "color": "blue"
         },
         "mode": "lines+markers",
         "name": "Training Loss",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9
         ],
         "y": [
          0.021150058773644384,
          0.009927520268620298,
          0.0070224220253442505,
          0.005653021558694826,
          0.0038868298218083124,
          0.0019298541554456626,
          0.004850066781269495,
          0.0014763173183782235,
          0.002247305340805557
         ]
        },
        {
         "line": {
          "color": "royalblue"
         },
         "mode": "lines",
         "name": "Validation Loss",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9
         ],
         "y": [
          0.016203861682914163,
          0.01559972119395665,
          0.014281954560179395,
          0.014060258972139788,
          0.018177554383588094,
          0.019375278688357592,
          0.01676829270153836,
          0.01908904293897482,
          0.015757452005140116
         ]
        }
       ],
       "layout": {
        "legend": {
         "x": 0.02,
         "y": 0.98
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Training and Validation Loss"
        },
        "xaxis": {
         "title": {
          "text": "Epochs"
         }
        },
        "yaxis": {
         "title": {
          "text": "Loss"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "acc = train_state['train_acc']\n",
    "val_acc = train_state['val_acc']\n",
    "loss = train_state['train_loss']\n",
    "val_loss = train_state['val_loss']\n",
    "\n",
    "epochs = list(range(1, len(acc) + 1))\n",
    "\n",
    "# Create interactive line chart\n",
    "fig = go.Figure()\n",
    "\n",
    "for y, name, color, mode in [(loss, 'Training Loss', 'blue', 'lines+markers'),\n",
    "                             (val_loss, 'Validation Loss', 'royalblue', 'lines')]:\n",
    "    fig.add_trace(go.Scatter(x=epochs, y=y, mode=mode, name=name, line=dict(color=color)))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Training and Validation Loss',\n",
    "    xaxis_title='Epochs',\n",
    "    yaxis_title='Loss',\n",
    "    legend=dict(x=0.02, y=0.98)\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090bc59c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "line": {
          "color": "blue"
         },
         "mode": "lines+markers",
         "name": "Training Accuracy",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9
         ],
         "y": [
          99.55448065173117,
          99.70723014256622,
          99.81860997963332,
          99.86952647657843,
          99.88225560081462,
          99.93953665987785,
          99.8536150712831,
          99.9681771894093,
          99.94908350305491
         ]
        },
        {
         "line": {
          "color": "royalblue"
         },
         "mode": "lines",
         "name": "Validation Accuracy",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9
         ],
         "y": [
          99.62797619047622,
          99.67261904761905,
          99.67261904761908,
          99.73214285714285,
          99.67261904761907,
          99.70238095238086,
          99.70238095238099,
          99.74702380952385,
          99.71726190476184
         ]
        }
       ],
       "layout": {
        "legend": {
         "x": 0.02,
         "y": 0.98
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Training and Validation Accuracy"
        },
        "xaxis": {
         "title": {
          "text": "Epochs"
         }
        },
        "yaxis": {
         "title": {
          "text": "Accuracy"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create interactive line chart for accuracy\n",
    "fig = go.Figure()\n",
    "\n",
    "for y, name, color, mode in [(acc, 'Training Accuracy', 'blue', 'lines+markers'),\n",
    "                             (val_acc, 'Validation Accuracy', 'royalblue', 'lines')]:\n",
    "    fig.add_trace(go.Scatter(x=epochs, y=y, mode=mode, name=name, line=dict(color=color)))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Training and Validation Accuracy',\n",
    "    xaxis_title='Epochs',\n",
    "    yaxis_title='Accuracy',\n",
    "    legend=dict(x=0.02, y=0.98)\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9016d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the loss & accuracy on the test set using the best available model\n",
    "\n",
    "classifier.load_state_dict(torch.load(train_state['model_filename'],weights_only=False))\n",
    "\n",
    "classifier = classifier.to(args.device)\n",
    "dataset.class_weights = dataset.class_weights.to(args.device)\n",
    "loss_func = nn.BCEWithLogitsLoss()\n",
    "\n",
    "dataset.set_split('test')\n",
    "batch_generator = generate_batches(dataset, \n",
    "                                   batch_size=args.batch_size, \n",
    "                                   device=args.device)\n",
    "running_loss = 0.\n",
    "running_acc = 0.\n",
    "classifier.eval()\n",
    "\n",
    "y_pred_list = []         # store predicted values for confusion matrix\n",
    "y_true_list = []        # ground truth values\n",
    "\n",
    "with torch.no_grad():  # Disable gradient computation\n",
    "  for batch_index, batch_dict in enumerate(batch_generator):\n",
    "    # compute the output\n",
    "    y_pred =  classifier(batch_dict['x_data'],\n",
    "                         x_lengths=batch_dict['x_length'])\n",
    "\n",
    "    # store predicted values and ground truth values for calculating confusion matrix\n",
    "    y_pred_prob = torch.sigmoid(y_pred).squeeze()\n",
    "    y_pred_binary = (y_pred_prob > 0.5).float()\n",
    "    y_pred_list.extend(y_pred_binary.cpu().numpy())\n",
    "    y_target = batch_dict['y_target'].float().unsqueeze(1)\n",
    "    y_true_list.extend(y_target.cpu().numpy())\n",
    "    \n",
    "    # compute the loss\n",
    "    loss = loss_func(y_pred, y_target) \n",
    "    loss_t = loss.item()\n",
    "    running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
    "\n",
    "    # compute the accuracy\n",
    "    acc_t = compute_accuracy(y_pred, y_target)\n",
    "    running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "\n",
    "train_state['test_loss'] = running_loss\n",
    "train_state['test_acc'] = running_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5529f5c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.014636302897581905;\n",
      "Test Accuracy: 99.68750000000007\n"
     ]
    }
   ],
   "source": [
    "print(\"Test loss: {};\".format(train_state['test_loss']))\n",
    "print(\"Test Accuracy: {}\".format(train_state['test_acc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6cb036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary classes: ['False', 'True']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "# For binary classification, we have two classes: False (0) and True (1)\n",
    "binary_classes = ['False', 'True']\n",
    "print(\"Binary classes:\", binary_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4031ead5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True       False  True\n",
      "Predicted             \n",
      "False       3503    10\n",
      "True          11  3196\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "cm = confusion_matrix(y_true_list, y_pred_list)\n",
    "cm_df = pd.DataFrame(cm.T, index=binary_classes, columns=binary_classes)\n",
    "cm_df.index.name = 'Predicted'\n",
    "cm_df.columns.name = 'True'\n",
    "print(cm_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9fb44c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      1.00      1.00      3514\n",
      "        True       1.00      1.00      1.00      3206\n",
      "\n",
      "    accuracy                           1.00      6720\n",
      "   macro avg       1.00      1.00      1.00      6720\n",
      "weighted avg       1.00      1.00      1.00      6720\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true_list, y_pred_list, target_names=binary_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaead303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "class_names = ['fake', 'real']\n",
    "name = 'CNN Model'\n",
    "cm = confusion_matrix(y_true_list, y_pred_list)\n",
    "plt.figure(figsize=(15, 10))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title(f'{name} confusion_matrix', fontsize=12)\n",
    "plt.ylabel('True Label', fontsize=10)\n",
    "plt.xlabel('Predicted Label', fontsize=10)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
